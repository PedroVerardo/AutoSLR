{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pramos/Documents/AutoSLR/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/home/pramos/Documents/AutoSLR/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pdf_handler import PDFHandler\n",
    "\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from docling.document_converter import DocumentConverter\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_and_names(folder_path):\n",
    "    all_paths = []\n",
    "    all_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            all_paths.append(os.path.join(root, file))\n",
    "            all_names.append(file)\n",
    "    return all_paths, all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to your folder with PDF files\n",
    "all_file_paths, all_file_names = find_all_paths_and_names(\"/home/pramos/Documents/AutoSLR/papers_pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regex_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) generic regex for all pdfs\n",
    "db_name = \"results/generic_regex.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    \n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "\n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "    try:\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[\"generic_section_title\"])\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) tagged regex extraction for all pdfs\n",
    "db_name = \"results/tagged_regex.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "PDFHandler.create_tables(conn)\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        # print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    \n",
    "    text, page_count, size_mode = PDFHandler.tagged_text_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "\n",
    "    try:\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[\"generic_section_title\"])\n",
    "        sections = [section for section in sections if getattr(section, 'is_bold', False) or getattr(section, 'size', 0) >= size_mode]\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 matches:\n",
      "Found 1 matches:\n",
      "Found 11 matches:\n",
      "Found 6 matches:\n",
      "Found 12 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 27 matches:\n",
      "Found 9 matches:\n",
      "Found 20 matches:\n",
      "Found 5 matches:\n",
      "Found 9 matches:\n",
      "Found 15 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Found 62 matches:\n",
      "Found 22 matches:\n",
      "Found 4 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 10 matches:\n",
      "Found 45 matches:\n",
      "Found 10 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 10 matches:\n",
      "Found 5 matches:\n",
      "Found 10 matches:\n",
      "Found 8 matches:\n",
      "Found 9 matches:\n",
      "Found 13 matches:\n",
      "Found 10 matches:\n",
      "Found 8 matches:\n",
      "Found 8 matches:\n",
      "Found 12 matches:\n",
      "Found 10 matches:\n",
      "Found 12 matches:\n",
      "Found 9 matches:\n",
      "Found 5 matches:\n",
      "Found 22 matches:\n",
      "Found 5 matches:\n",
      "Found 4 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 6 matches:\n",
      "Found 55 matches:\n",
      "Found 36 matches:\n",
      "Found 19 matches:\n",
      "Found 16 matches:\n",
      "Found 14 matches:\n",
      "Found 9 matches:\n",
      "Found 12 matches:\n",
      "Found 6 matches:\n",
      "Found 3 matches:\n",
      "Found 26 matches:\n",
      "Found 8 matches:\n",
      "Found 20 matches:\n",
      "Found 13 matches:\n",
      "Found 6 matches:\n",
      "Found 5 matches:\n",
      "Found 14 matches:\n",
      "Found 9 matches:\n",
      "Found 48 matches:\n",
      "Found 8 matches:\n",
      "Found 10 matches:\n",
      "Found 10 matches:\n",
      "Found 7 matches:\n",
      "Found 5 matches:\n",
      "Found 27 matches:\n",
      "Found 17 matches:\n",
      "Found 9 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 45 matches:\n",
      "Found 11 matches:\n",
      "Found 14 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Error processing Arcaini2020.pdf: Error binding parameter 1 - probably unsupported type.\n",
      "Found 10 matches:\n",
      "Found 9 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 7 matches:\n",
      "Found 6 matches:\n",
      "Found 3 matches:\n",
      "Found 7 matches:\n",
      "Found 14 matches:\n",
      "Found 15 matches:\n",
      "Found 7 matches:\n",
      "Found 8 matches:\n"
     ]
    }
   ],
   "source": [
    "#3) specific regex extraction for all pdfs\n",
    "db_name = \"results/specific_regex.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "PDFHandler.create_tables(conn)\n",
    "\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    \n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "\n",
    "    try:\n",
    "        section_type = df[df['pdf_name'] == name[:-4]]['section_type'].values[0]\n",
    "        # print(f\"Processing {name} with section type: {section_type}\")\n",
    "        if section_type not in PDFHandler.regex_patterns:\n",
    "            # print(f\"Section type {section_type} not found in regex patterns.\")\n",
    "            continue\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[section_type],  debug=True)\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) voting policy for all pdfs\n",
    "db_name = \"results/voting_policy.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "PDFHandler.create_tables(conn)\n",
    "\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    \n",
    "    text, page_count, size_mode = PDFHandler.tagged_text_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "\n",
    "    try:\n",
    "        section_type = df[df['pdf_name'] == name[:-4]]['section_type'].values[0]\n",
    "        if section_type not in PDFHandler.regex_patterns:\n",
    "            # print(f\"Section type {section_type} not found in regex patterns.\")\n",
    "            continue\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[section_type], debug=True)\n",
    "        sections = PDFHandler.voting_policy(sections, size_mode)\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment2prompt(sections: list) -> str:\n",
    "   prompt = \"\"\"Analyze the following potential section titles extracted by regex pattern matching. Some may be actual section headers while others could be false positives (table entries, references, footnotes, etc.).\n",
    "\n",
    "Please identify which ones are most likely to be legitimate section titles for an academic paper or document:\n",
    "\n",
    "\"\"\"\n",
    "   \n",
    "   for idx, section in enumerate(sections):\n",
    "       prompt += f\"({idx}) {section.section_number}. {section.section_title}\\n\"\n",
    "   \n",
    "   prompt += \"\"\"\n",
    "            EVALUATION CRITERIA:\n",
    "            - Look for typical section patterns (Introduction, Methods, Results, Discussion, Conclusion, etc.)\n",
    "            - Consider formatting consistency and logical flow\n",
    "            - Exclude obvious false positives like:\n",
    "            - Table captions or figure titles\n",
    "            - Reference entries or citations\n",
    "            - Page headers/footers\n",
    "            - Numbered lists within paragraphs\n",
    "            - Partial sentences or fragments\n",
    "\n",
    "            Please respond with a JSON object containing the indices of legitimate section titles:\n",
    "\n",
    "            {\n",
    "            \"selected_sections\": [0, 2, 5, 8]\n",
    "            }\n",
    "\n",
    "            Response:\"\"\"\n",
    "   \n",
    "   return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_sections(response_text: str) -> list:\n",
    "    # Procura por padrão JSON no texto\n",
    "    json_pattern = r'\\{[^}]*\"selected_sections\"[^}]*\\[[^\\]]*\\][^}]*\\}'\n",
    "    match = re.search(json_pattern, response_text)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            json_data = json.loads(match.group())\n",
    "            return json_data.get(\"selected_sections\", [])\n",
    "        except json.JSONDecodeError:\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "def ask_llm(prompt, context: list[str] = [], model=\"deepseek-r1:1.5b\"):\n",
    "    try:\n",
    "\n",
    "        if isinstance(prompt, list):\n",
    "            prompt = \"\\n\".join(str(item) for item in prompt)\n",
    "\n",
    "        if isinstance(context, list):\n",
    "            context = \"\\n\".join(str(item) for item in context)\n",
    "\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            f'{OLLAMA_URL}/api/generate',\n",
    "            json=data,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for line in response.text.splitlines():\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    json_response = json.loads(line)\n",
    "                    if 'response' in json_response:\n",
    "                        full_response += json_response['response']\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        return full_response\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return \"Error: Cannot connect to Ollama server\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: Request failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid sections found for Arcaini2020.pdf using LLM.\n",
      "No valid sections found for Švogor2019.pdf using LLM.\n",
      "No valid sections found for Ha2019-icse.pdf using LLM.\n",
      "No valid sections found for Liu2022.pdf using LLM.\n",
      "No valid sections found for Temple2021.pdf using LLM.\n",
      "No valid sections found for Weber2021.pdf using LLM.\n",
      "No valid sections found for schmid2022.pdf using LLM.\n",
      "No valid sections found for hugo2021-tse.pdf using LLM.\n",
      "No valid sections found for shaghayegh2022-splc.pdf using LLM.\n",
      "No valid sections found for liang2024cc.pdf using LLM.\n"
     ]
    }
   ],
   "source": [
    "#5) Local llms to analyze the generic regex\n",
    "\n",
    "model = \"llama3:8b\"\n",
    "db_name = f\"results/local_llms{model}.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    \n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "\n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "    try:\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[\"generic_section_title\"])\n",
    "        prompt = segment2prompt(sections)\n",
    "        answare = ask_llm(prompt, model=\"llama3:8b\")\n",
    "        if answare.startswith(\"Error:\") or answare == \"\":\n",
    "            print(f\"LLM error for {name}: {answare}\")\n",
    "            continue\n",
    "        position_list = extract_selected_sections(answare)\n",
    "        if not position_list:\n",
    "            print(f\"No valid sections found for {name} using LLM.\")\n",
    "            continue\n",
    "        sections = [sections[i] for i in position_list if i < len(sections)]\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf_to_gemini(pdf_path):\n",
    "        \"\"\"Faz upload do PDF para o Gemini\"\"\"\n",
    "        try:\n",
    "            # Upload do arquivo para o Gemini\n",
    "            uploaded_file = genai.upload_file(pdf_path)\n",
    "            print(f\"Arquivo enviado: {uploaded_file.name}\")\n",
    "            \n",
    "            # Aguarda o processamento do arquivo\n",
    "            while uploaded_file.state.name == \"PROCESSING\":\n",
    "                print(\"Processando arquivo...\")\n",
    "                time.sleep(2)\n",
    "                uploaded_file = genai.get_file(uploaded_file.name)\n",
    "            \n",
    "            if uploaded_file.state.name == \"FAILED\":\n",
    "                raise ValueError(\"Falha no processamento do arquivo\")\n",
    "                \n",
    "            return uploaded_file\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no upload do PDF: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#6) global llms \n",
    "db_name = \"results/extern_llm-gemini.db\"\n",
    "model_names = [\"gemini-2.5-flash-preview-05-20\", \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"]\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API\")\n",
    "\n",
    "# PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')\n",
    "PDFHandler.create_tables(conn)\n",
    "\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    upload_pdf = upload_pdf_to_gemini(path)\n",
    "\n",
    "    prompt = PDFHandler.llm_prompt\n",
    "\n",
    "    if upload_pdf is None:\n",
    "        print(f\"Error uploading PDF: {name}\")\n",
    "        continue\n",
    "    try:\n",
    "        doc = PDFHandler.try_open(path)\n",
    "        if doc is None:\n",
    "            print(f\"Error opening the PDF: {name}\")\n",
    "            continue\n",
    "        text, page_count = PDFHandler.simple_extraction(doc)\n",
    "        response = model.generate_content([prompt, upload_pdf])\n",
    "        response_text = response.text\n",
    "        sections_data = json.loads(response_text)\n",
    "\n",
    "        pattern = r'\\{.*?\\}'\n",
    "        match = re.findall(pattern, response_text, re.DOTALL)\n",
    "\n",
    "        if not match:\n",
    "            print(f\"No valid JSON sections found in response for {name}.\")\n",
    "            continue\n",
    "    \n",
    "        else:\n",
    "            try:\n",
    "                retrived_json = json.loads(match) \n",
    "            except:\n",
    "                print(\"Could not load json\")\n",
    "                continue\n",
    "        \n",
    "\n",
    "        section_arr = []\n",
    "        for section in retrived_json.get(\"sections\", []):\n",
    "            section_arr.append(PDFHandler.find_pattern_in_text(text, section))\n",
    "        \n",
    "        pdf_name = os.path.basename(path)\n",
    "        \n",
    "        cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "        pdf_id = cursor.fetchone()\n",
    "            \n",
    "        if not pdf_id:\n",
    "            cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "            pdf_id = cursor.lastrowid\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, section_arr, pdf_id)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name} with Gemini: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7) ORC extraction\n",
    "db_name = \"results/ORC_tag_extraction.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "\n",
    "    try:\n",
    "        sections = PDFHandler.orc_extraction_html(path)\n",
    "        if not sections:\n",
    "            print(f\"No sections found for {name} using ORC extraction.\")\n",
    "            continue\n",
    "        sections = [section for section in sections if section.section_title.strip() != \"\"]\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
