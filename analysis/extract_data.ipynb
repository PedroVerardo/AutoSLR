{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "from ollama_tools import ask_llm\n",
    "import fitz\n",
    "import os\n",
    "from ollama import chat\n",
    "from ollama import Client\n",
    "from ollama import ChatResponse\n",
    "from ollama import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(host='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>sampling method</th>\n",
       "      <th>systemname</th>\n",
       "      <th>domain</th>\n",
       "      <th>nfp</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset</th>\n",
       "      <th>technique</th>\n",
       "      <th>partition method</th>\n",
       "      <th>evaluation metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alshehri2023</td>\n",
       "      <td>reamostragem SMOTE</td>\n",
       "      <td>Eclipse</td>\n",
       "      <td>system files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[AdaBoost com J48, J48]</td>\n",
       "      <td>Validação cruzada</td>\n",
       "      <td>[Recall , Precision, Medida F ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alves2020</td>\n",
       "      <td>[Coverage-based    , Solver-based, Randomized ...</td>\n",
       "      <td>x264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tempo de codificação e codificação, tamanho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/jualvespereira/ICPE2020</td>\n",
       "      <td>regressão linear múltipla</td>\n",
       "      <td>NI</td>\n",
       "      <td>MRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arcaini2020</td>\n",
       "      <td>Não identifiquei</td>\n",
       "      <td>No identificado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ballesteros2021</td>\n",
       "      <td>NI</td>\n",
       "      <td>[x264, Wget, Berkeley DB Memory, Sensor Networ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Population Size / Archive Size: 400; Number of...</td>\n",
       "      <td>SI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regressão linear</td>\n",
       "      <td>NI</td>\n",
       "      <td>Coverage Metric (CM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chen2022</td>\n",
       "      <td>amostragem adaptativa com d-Simplexed</td>\n",
       "      <td>Spark</td>\n",
       "      <td>Database System</td>\n",
       "      <td>Count,Executor Memory,Executor Threads, Memory...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rede Neural Multicamadas (NN)</td>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>MAPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tipu2022:cc</td>\n",
       "      <td>Random Sampling</td>\n",
       "      <td>[MPI-I/O, SEG-Y I/O]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Number of MPI node, MPI processes per node, S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artificial Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[accuracy, MSE, MAE, MAPE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>valov2020:icpe</td>\n",
       "      <td>amostragem pseudoaleatória</td>\n",
       "      <td>[BZIP2, GZIP, XZ, FLAC, x264]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[árvores de regressão, Regressão linear simple]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MAPE, LOOCV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>vitui2021:ese</td>\n",
       "      <td>Amostragem aleatória</td>\n",
       "      <td>[Open-Src, Entprz. 1, Entprz. 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Random Forest, XGBoost trees, Multi-Layer Per...</td>\n",
       "      <td>[cross-validation, validação cruzada leave-one...</td>\n",
       "      <td>[Median Percentage Deviation, MAPE, MAE, (MSE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>yufei2024:jss</td>\n",
       "      <td>[Random Sampling, Neighborhood Sampling, Input...</td>\n",
       "      <td>[SQLite, BDB-C, BDB-J, LLVM, Sac, Apache, x264...</td>\n",
       "      <td>[Database, Compiler, Web Server, Video Encoder...</td>\n",
       "      <td>[Execution Time, Response Time, Video Encoding...</td>\n",
       "      <td>Execution</td>\n",
       "      <td>https://github.com/RSFIN/RSFIN/tree/master/data</td>\n",
       "      <td>[Artificial Neural Networks (ANN), Deep Learni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Švogor2019</td>\n",
       "      <td>[SCAF com algoritmo genetico, , SCAF usando o ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Component Allocation Framework (SCAF)</td>\n",
       "      <td>NI</td>\n",
       "      <td>Intervalo de confiança</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference                                    sampling method  \\\n",
       "0      Alshehri2023                                 reamostragem SMOTE   \n",
       "1         Alves2020  [Coverage-based    , Solver-based, Randomized ...   \n",
       "2       Arcaini2020                                  Não identifiquei    \n",
       "3   Ballesteros2021                                                 NI   \n",
       "4          Chen2022              amostragem adaptativa com d-Simplexed   \n",
       "..              ...                                                ...   \n",
       "59      tipu2022:cc                                    Random Sampling   \n",
       "60   valov2020:icpe                         amostragem pseudoaleatória   \n",
       "61    vitui2021:ese                               Amostragem aleatória   \n",
       "62    yufei2024:jss  [Random Sampling, Neighborhood Sampling, Input...   \n",
       "63       Švogor2019  [SCAF com algoritmo genetico, , SCAF usando o ...   \n",
       "\n",
       "                                           systemname  \\\n",
       "0                                             Eclipse   \n",
       "1                                                x264   \n",
       "2                                     No identificado   \n",
       "3   [x264, Wget, Berkeley DB Memory, Sensor Networ...   \n",
       "4                                               Spark   \n",
       "..                                                ...   \n",
       "59                               [MPI-I/O, SEG-Y I/O]   \n",
       "60                      [BZIP2, GZIP, XZ, FLAC, x264]   \n",
       "61                   [Open-Src, Entprz. 1, Entprz. 2]   \n",
       "62  [SQLite, BDB-C, BDB-J, LLVM, Sac, Apache, x264...   \n",
       "63                                                NaN   \n",
       "\n",
       "                                               domain  \\\n",
       "0                                        system files   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                     Database System   \n",
       "..                                                ...   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "61                                                NaN   \n",
       "62  [Database, Compiler, Web Server, Video Encoder...   \n",
       "63                                                NaN   \n",
       "\n",
       "                                                  nfp   strategy  \\\n",
       "0                                                 NaN        NaN   \n",
       "1         Tempo de codificação e codificação, tamanho        NaN   \n",
       "2                                                 NaN        NaN   \n",
       "3   Population Size / Archive Size: 400; Number of...         SI   \n",
       "4   Count,Executor Memory,Executor Threads, Memory...        NaN   \n",
       "..                                                ...        ...   \n",
       "59  [Number of MPI node, MPI processes per node, S...        NaN   \n",
       "60                                                NaN        NaN   \n",
       "61                                                NaN        NaN   \n",
       "62  [Execution Time, Response Time, Video Encoding...  Execution   \n",
       "63                                                NaN        NaN   \n",
       "\n",
       "                                            dataset  \\\n",
       "0                                               NaN   \n",
       "1        https://github.com/jualvespereira/ICPE2020   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "..                                              ...   \n",
       "59                                              NaN   \n",
       "60                                              NaN   \n",
       "61                                              NaN   \n",
       "62  https://github.com/RSFIN/RSFIN/tree/master/data   \n",
       "63                                              NaN   \n",
       "\n",
       "                                            technique  \\\n",
       "0                             [AdaBoost com J48, J48]   \n",
       "1                           regressão linear múltipla   \n",
       "2                                                 NaN   \n",
       "3                                    regressão linear   \n",
       "4                       Rede Neural Multicamadas (NN)   \n",
       "..                                                ...   \n",
       "59                         Artificial Neural Networks   \n",
       "60    [árvores de regressão, Regressão linear simple]   \n",
       "61  [Random Forest, XGBoost trees, Multi-Layer Per...   \n",
       "62  [Artificial Neural Networks (ANN), Deep Learni...   \n",
       "63     Software Component Allocation Framework (SCAF)   \n",
       "\n",
       "                                     partition method  \\\n",
       "0                                   Validação cruzada   \n",
       "1                                                  NI   \n",
       "2                                                 NaN   \n",
       "3                                                  NI   \n",
       "4                                           Bootstrap   \n",
       "..                                                ...   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "61  [cross-validation, validação cruzada leave-one...   \n",
       "62                                                NaN   \n",
       "63                                                 NI   \n",
       "\n",
       "                                    evaluation metric  \n",
       "0                     [Recall , Precision, Medida F ]  \n",
       "1                                                 MRE  \n",
       "2                                                 NaN  \n",
       "3                                Coverage Metric (CM)  \n",
       "4                                                MAPE  \n",
       "..                                                ...  \n",
       "59                         [accuracy, MSE, MAE, MAPE]  \n",
       "60                                      [MAPE, LOOCV]  \n",
       "61  [Median Percentage Deviation, MAPE, MAE, (MSE,...  \n",
       "62                                                NaN  \n",
       "63                             Intervalo de confiança  \n",
       "\n",
       "[64 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data-extration.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "rq_sheets = [\"RQ2\", \"RQ3_Systems\", \"RQ4_Learning\", \"RQ5_Partition_Method\", \"RQ5_Metric\"]\n",
    "\n",
    "def extract_citation_key(cite):\n",
    "    if isinstance(cite, str):\n",
    "        match = re.search(r\"\\\\cite{(.+?)}\", cite)\n",
    "        return match.group(1) if match else cite\n",
    "    return cite\n",
    "\n",
    "processed_sheets = {}\n",
    "for sheet in rq_sheets:\n",
    "    df = xls.parse(sheet)\n",
    "    df.columns = [str(col).strip().lower() for col in df.columns]\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('^unnamed')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('^comentário')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('^obs:')]\n",
    "    \n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    if \"reference\" in df.columns:\n",
    "        df[\"reference\"] = df[\"reference\"].apply(extract_citation_key)\n",
    "        \n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col != \"reference\":\n",
    "                agg_dict[col] = lambda x: list(x.dropna().unique()) if len(x.dropna()) > 0 else np.nan\n",
    "        \n",
    "        df = df.groupby(\"reference\", as_index=False).agg(agg_dict)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col != \"reference\":\n",
    "                df[col] = df[col].apply(lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x)\n",
    "\n",
    "    processed_sheets[sheet] = df\n",
    "\n",
    "merged_df = processed_sheets[rq_sheets[0]]\n",
    "for sheet in rq_sheets[1:]:\n",
    "    merged_df = merged_df.merge(processed_sheets[sheet], on=\"reference\", how=\"outer\")\n",
    "\n",
    "merged_df.columns = [col.split('.')[-1] if '.' in col else col for col in merged_df.columns]\n",
    "\n",
    "merged_df.drop(columns=[\"related\", \"ref\", \"cite\"], inplace=True)\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>sampling method</th>\n",
       "      <th>systemname</th>\n",
       "      <th>domain</th>\n",
       "      <th>nfp</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset</th>\n",
       "      <th>technique</th>\n",
       "      <th>partition method</th>\n",
       "      <th>evaluation metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lesoil2024</td>\n",
       "      <td>[K-means, HDBScan, Amostragem aleatória, Submo...</td>\n",
       "      <td>[gcc, ImageMagick, lingeling, nodeJS, poppler,...</td>\n",
       "      <td>[.c programs, images, SAT formulae, .js script...</td>\n",
       "      <td>[size, ctime, exec, size, time, #confl.,#reduc...</td>\n",
       "      <td>EX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OLS Regression, Desicion Tree, Random forest,...</td>\n",
       "      <td>NI</td>\n",
       "      <td>Mean Absolute Percentage Error (MAPE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference                                    sampling method  \\\n",
       "46  lesoil2024  [K-means, HDBScan, Amostragem aleatória, Submo...   \n",
       "\n",
       "                                           systemname  \\\n",
       "46  [gcc, ImageMagick, lingeling, nodeJS, poppler,...   \n",
       "\n",
       "                                               domain  \\\n",
       "46  [.c programs, images, SAT formulae, .js script...   \n",
       "\n",
       "                                                  nfp strategy dataset  \\\n",
       "46  [size, ctime, exec, size, time, #confl.,#reduc...       EX     NaN   \n",
       "\n",
       "                                            technique partition method  \\\n",
       "46  [OLS Regression, Desicion Tree, Random forest,...               NI   \n",
       "\n",
       "                        evaluation metric  \n",
       "46  Mean Absolute Percentage Error (MAPE)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df[\"reference\"] == \"lesoil2024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"reference\"] = merged_df[\"reference\"].str.replace(\":\", \"_\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_message(topic: str, context: str, question: str, some_answer_examples: str,answer_prefix: str, base_text: str, text_example:str, answer_text_example:str, model: str) -> str:\n",
    "    message = [{\n",
    "        'role': \"system\",\n",
    "        'content': f\"\"\"You are an expert scientific article analyzer. Your task is to extract specific information \n",
    "        from scientific texts based on provided questions and context. When asked about {topic}, understand that {context}\n",
    "        Examples include: {some_answer_examples}\n",
    "        Your answer should be concise and directly address the question based on the provided text, starting with the phrase:{answer_prefix}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'role': \"user\",\n",
    "        'content': f\"\"\"Please answer the question: {question}, based on the following text: {base_text}\"\"\"\n",
    "    },{\n",
    "        'role': \"assistant\",\n",
    "        'content': f\"\"\"Question: {question}\\n base_text: {text_example}\\nAnswer: {answer_text_example}\n",
    "        \"\"\"\n",
    "    }]\n",
    "\n",
    "    return message\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_list = merged_df[\"reference\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_metrics = [\"sampling method\", \"dataset\", \"technique\", \"partition method\", \"evaluation metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sampling method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/AutoSLR/venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sampling method'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     10\u001b[0m     ref \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m     result_dict[ref] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtechnique\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtechnique\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartition method\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartition method\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation metric\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation metric\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     19\u001b[0m result_dict\n",
      "File \u001b[0;32m~/Documents/AutoSLR/venv/lib64/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Documents/AutoSLR/venv/lib64/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Documents/AutoSLR/venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sampling method'"
     ]
    }
   ],
   "source": [
    "# def extract_citation_key(cite):\n",
    "#     match = re.search(r\"\\\\cite{(.+?)}\", cite)\n",
    "#     return match.group(1) if match else cite\n",
    "\n",
    "# df[\"reference\"] = df[\"reference\"].apply(extract_citation_key)\n",
    "\n",
    "# result_dict = {}\n",
    "\n",
    "# for _, row in df.iterrows():\n",
    "#     ref = row[\"reference\"]\n",
    "#     result_dict[ref] = {\n",
    "#         \"sampling method\": row[\"sampling method\"],\n",
    "#         \"dataset\": row[\"dataset\"],\n",
    "#         \"technique\": row[\"technique\"],\n",
    "#         \"partition method\": row[\"partition method\"],\n",
    "#         \"evaluation metric\": row[\"evaluation metric\"]\n",
    "#     }\n",
    "\n",
    "# result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm_models = [\"deepseek-r1:32b\", \"magistral:24b\", \"llama4:latest\"] #testar o llama 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_tables(db_path: str, llm_models: list):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS llm_models (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            model_name TEXT NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS llm_responses (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            model_id INTEGER,\n",
    "            pdf_name varchar(255),\n",
    "            prompt_technique varchar(255),\n",
    "            text_segmentation_stategy varchar(255),\n",
    "            metric varchar(255),\n",
    "            response TEXT,\n",
    "            FOREIGN KEY (model_id) REFERENCES llm_models(id)\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    for model in llm_models:\n",
    "        cursor.execute('INSERT INTO llm_models (model_name) VALUES (?)', (model,))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_llm_response(db_path: str, model_name: str, pdf_name: str, prompt_technique: str, metric: str, response: str, text_segmentation_stategy: str):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('SELECT id FROM llm_models WHERE model_name = ?', (model_name,))\n",
    "    model_id = cursor.fetchone()\n",
    "    if not model_id:\n",
    "        cursor.execute('INSERT INTO llm_models (model_name) VALUES (?)', (model_name,))\n",
    "        conn.commit()\n",
    "        cursor.execute('SELECT id FROM llm_models WHERE model_name = ?', (model_name,))\n",
    "        model_id = cursor.fetchone()\n",
    "    \n",
    "    if model_id:\n",
    "        cursor.execute('''\n",
    "            INSERT INTO llm_responses (model_id, pdf_name, prompt_technique, metric, response, text_segmentation_stategy)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (model_id, pdf_name, prompt_technique, metric, response, text_segmentation_stategy))\n",
    "        \n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(f\"Model {model_name} not found in the database.\")\n",
    "    \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_and_names(folder_path):\n",
    "    all_paths = []\n",
    "    all_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            all_paths.append(os.path.join(root, file))\n",
    "            all_names.append(file)\n",
    "    return all_paths, all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_extraction(path: str) -> dict[int, str]:\n",
    "        \"\"\"This function extracts text from a PDF file and returns the text along with the number of pages.\n",
    "\n",
    "        Args:\n",
    "            doc (fitz.Document): The PDF document object\n",
    "\n",
    "        Returns:\n",
    "            tuple[str, int]: The text inside the pdf(without any cleaning) and page count\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = \"\"\n",
    "            total_pages = 0\n",
    "            doc = fitz.open(path)\n",
    "            for idx, page in enumerate(doc):\n",
    "                text += f\"<--page_start:{idx+1}-->\"\n",
    "                text +=  page.get_text()\n",
    "                text += f\"<--page_end:{idx+1}-->\"\n",
    "                total_pages += 1\n",
    "            return text, total_pages\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e} in {__file__} \")\n",
    "            return \"\", 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Alshehri2020.pdf (ID: 21)\n",
      "Error extracting text from Alshehri2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: Arcaini2020.pdf (ID: 16)\n",
      "Error extracting text from Arcaini2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: Chen2022.pdf (ID: 22)\n",
      "Error extracting text from Chen2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: Damasceno2021.pdf (ID: 23)\n",
      "Error extracting text from Damasceno2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: Dorn2023ese.pdf (ID: 77)\n",
      "Error extracting text from Dorn2023ese.pdf: name '__file__' is not defined\n",
      "Processing PDF: Gao2021-ICSE.pdf (ID: 24)\n",
      "Error extracting text from Gao2021-ICSE.pdf: name '__file__' is not defined\n",
      "Processing PDF: García2021.pdf (ID: 25)\n",
      "Error extracting text from García2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: H. Martin2022.pdf (ID: 17)\n",
      "Error extracting text from H. Martin2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: Ha-2019ICSME.pdf (ID: 26)\n",
      "Error extracting text from Ha-2019ICSME.pdf: name '__file__' is not defined\n",
      "Processing PDF: Ha2019-icse.pdf (ID: 27)\n",
      "Error extracting text from Ha2019-icse.pdf: name '__file__' is not defined\n",
      "Processing PDF: Iorio2019.pdf (ID: 28)\n",
      "Error extracting text from Iorio2019.pdf: name '__file__' is not defined\n",
      "Processing PDF: Iqbal2022.pdf (ID: 29)\n",
      "Error extracting text from Iqbal2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: Iqbal2023.pdf (ID: 30)\n",
      "Error extracting text from Iqbal2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: Kaltenecker2019.pdf (ID: 31)\n",
      "Error extracting text from Kaltenecker2019.pdf: name '__file__' is not defined\n",
      "Processing PDF: Kaltenecker2023ese.pdf (ID: 78)\n",
      "Error extracting text from Kaltenecker2023ese.pdf: name '__file__' is not defined\n",
      "Processing PDF: Krishna2021.pdf (ID: 32)\n",
      "Error extracting text from Krishna2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: Liu2022.pdf (ID: 33)\n",
      "Error extracting text from Liu2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: Muhlbauer2020.pdf (ID: 34)\n",
      "Error extracting text from Muhlbauer2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: Muhlbauer2023.pdf (ID: 35)\n",
      "Error extracting text from Muhlbauer2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: Nair2020.pdf (ID: 36)\n",
      "Error extracting text from Nair2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: OH2023.pdf (ID: 37)\n",
      "Error extracting text from OH2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: Salman2023.pdf (ID: 38)\n",
      "Error extracting text from Salman2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: Silva2023.pdf (ID: 39)\n",
      "Error extracting text from Silva2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: Temple2021.pdf (ID: 40)\n",
      "Error extracting text from Temple2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: Vitui2021ese.pdf (ID: 79)\n",
      "Error extracting text from Vitui2021ese.pdf: name '__file__' is not defined\n",
      "Processing PDF: Weber2021.pdf (ID: 41)\n",
      "Error extracting text from Weber2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: Xiang2022.pdf (ID: 42)\n",
      "Error extracting text from Xiang2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: Yu2021.pdf (ID: 43)\n",
      "Error extracting text from Yu2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: alves2020-icpe.pdf (ID: 44)\n",
      "Error extracting text from alves2020-icpe.pdf: name '__file__' is not defined\n",
      "Processing PDF: amraoui2022_splc.pdf (ID: 1)\n",
      "Error extracting text from amraoui2022_splc.pdf: name '__file__' is not defined\n",
      "Processing PDF: ballesteros2021.pdf (ID: 45)\n",
      "Error extracting text from ballesteros2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: cao2023ase.pdf (ID: 80)\n",
      "Error extracting text from cao2023ase.pdf: name '__file__' is not defined\n",
      "Processing PDF: chen2020.pdf (ID: 46)\n",
      "Error extracting text from chen2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: chen2023.pdf (ID: 47)\n",
      "Error extracting text from chen2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: cheng2023_tse.pdf (ID: 2)\n",
      "Error extracting text from cheng2023_tse.pdf: name '__file__' is not defined\n",
      "Processing PDF: damasceno2019.pdf (ID: 48)\n",
      "Error extracting text from damasceno2019.pdf: name '__file__' is not defined\n",
      "Processing PDF: david2024-splc.pdf (ID: 66)\n",
      "Error extracting text from david2024-splc.pdf: name '__file__' is not defined\n",
      "Processing PDF: dorn2020_vamos.pdf (ID: 3)\n",
      "Error extracting text from dorn2020_vamos.pdf: name '__file__' is not defined\n",
      "Processing PDF: friesel2022_icse.pdf (ID: 4)\n",
      "Error extracting text from friesel2022_icse.pdf: name '__file__' is not defined\n",
      "Processing PDF: ghofrani2019.pdf (ID: 49)\n",
      "Error extracting text from ghofrani2019.pdf: name '__file__' is not defined\n",
      "Processing PDF: gong2022_msr.pdf (ID: 5)\n",
      "Error extracting text from gong2022_msr.pdf: name '__file__' is not defined\n",
      "Processing PDF: gong2023_fse.pdf (ID: 6)\n",
      "Error extracting text from gong2023_fse.pdf: name '__file__' is not defined\n",
      "Processing PDF: hugo2021-tse.pdf (ID: 67)\n",
      "Error extracting text from hugo2021-tse.pdf: name '__file__' is not defined\n",
      "Processing PDF: isaev2023_hpcc.pdf (ID: 7)\n",
      "Error extracting text from isaev2023_hpcc.pdf: name '__file__' is not defined\n",
      "Processing PDF: jose-miguel2023-jss.pdf (ID: 68)\n",
      "Error extracting text from jose-miguel2023-jss.pdf: name '__file__' is not defined\n",
      "Processing PDF: kolesnikov2019_emse.pdf (ID: 8)\n",
      "Error extracting text from kolesnikov2019_emse.pdf: name '__file__' is not defined\n",
      "Processing PDF: kolesnikov2019_ssm.pdf (ID: 9)\n",
      "Error extracting text from kolesnikov2019_ssm.pdf: name '__file__' is not defined\n",
      "Processing PDF: larissa2024-hpdc.pdf (ID: 69)\n",
      "Error extracting text from larissa2024-hpdc.pdf: name '__file__' is not defined\n",
      "Processing PDF: lesoil2021-icps.pdf (ID: 50)\n",
      "Error extracting text from lesoil2021-icps.pdf: name '__file__' is not defined\n",
      "Processing PDF: lesoil2021.pdf (ID: 51)\n",
      "Error extracting text from lesoil2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: lesoil2022-icps.pdf (ID: 52)\n",
      "Error extracting text from lesoil2022-icps.pdf: name '__file__' is not defined\n",
      "Processing PDF: lesoil2022_vamos.pdf (ID: 10)\n",
      "Error extracting text from lesoil2022_vamos.pdf: name '__file__' is not defined\n",
      "Processing PDF: lesoil2023.pdf (ID: 18)\n",
      "Error extracting text from lesoil2023.pdf: name '__file__' is not defined\n",
      "Processing PDF: lesoil2024.pdf (ID: 19)\n",
      "Error extracting text from lesoil2024.pdf: name '__file__' is not defined\n",
      "Processing PDF: li2019_ssm.pdf (ID: 81)\n",
      "Error extracting text from li2019_ssm.pdf: name '__file__' is not defined\n",
      "Processing PDF: li2020-ase.pdf (ID: 53)\n",
      "Error extracting text from li2020-ase.pdf: name '__file__' is not defined\n",
      "Processing PDF: li2020.pdf (ID: 54)\n",
      "Error extracting text from li2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: li2023_scis.pdf (ID: 82)\n",
      "Error extracting text from li2023_scis.pdf: name '__file__' is not defined\n",
      "Processing PDF: liang2024cc.pdf (ID: 83)\n",
      "Error extracting text from liang2024cc.pdf: name '__file__' is not defined\n",
      "Processing PDF: lima2022ese.pdf (ID: 84)\n",
      "Error extracting text from lima2022ese.pdf: name '__file__' is not defined\n",
      "Processing PDF: lukas2024-splc.pdf (ID: 70)\n",
      "Error extracting text from lukas2024-splc.pdf: name '__file__' is not defined\n",
      "Processing PDF: magrin2022_twc.pdf (ID: 11)\n",
      "Error extracting text from magrin2022_twc.pdf: name '__file__' is not defined\n",
      "Processing PDF: marcén2022ssm.pdf (ID: 85)\n",
      "Error extracting text from marcén2022ssm.pdf: name '__file__' is not defined\n",
      "Processing PDF: martin2021.pdf (ID: 55)\n",
      "Error extracting text from martin2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: mathieu2023-splc.pdf (ID: 71)\n",
      "Error extracting text from mathieu2023-splc.pdf: name '__file__' is not defined\n",
      "Processing PDF: mehlstäubl2022.pdf (ID: 56)\n",
      "Error extracting text from mehlstäubl2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: metzger2024computing.pdf (ID: 86)\n",
      "Error extracting text from metzger2024computing.pdf: name '__file__' is not defined\n",
      "Processing PDF: muhlbauer2023_icse.pdf (ID: 12)\n",
      "Error extracting text from muhlbauer2023_icse.pdf: name '__file__' is not defined\n",
      "Processing PDF: mukelabai2023-tse.pdf (ID: 72)\n",
      "Error extracting text from mukelabai2023-tse.pdf: name '__file__' is not defined\n",
      "Processing PDF: nascimento2021-bigdata.pdf (ID: 57)\n",
      "Error extracting text from nascimento2021-bigdata.pdf: name '__file__' is not defined\n",
      "Processing PDF: peeters2021_ida.pdf (ID: 13)\n",
      "Error extracting text from peeters2021_ida.pdf: name '__file__' is not defined\n",
      "Processing PDF: peng2023ese.pdf (ID: 87)\n",
      "Error extracting text from peng2023ese.pdf: name '__file__' is not defined\n",
      "Processing PDF: ros2020_emse.pdf (ID: 14)\n",
      "Error extracting text from ros2020_emse.pdf: name '__file__' is not defined\n",
      "Processing PDF: safdar2020_ase.pdf (ID: 88)\n",
      "Error extracting text from safdar2020_ase.pdf: name '__file__' is not defined\n",
      "Processing PDF: sakhrawi2019_cc.pdf (ID: 89)\n",
      "Error extracting text from sakhrawi2019_cc.pdf: name '__file__' is not defined\n",
      "Processing PDF: schmid2022.pdf (ID: 58)\n",
      "Error extracting text from schmid2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: seewal2021_ijpp.pdf (ID: 90)\n",
      "Error extracting text from seewal2021_ijpp.pdf: name '__file__' is not defined\n",
      "Processing PDF: sewal2024cc.pdf (ID: 91)\n",
      "Error extracting text from sewal2024cc.pdf: name '__file__' is not defined\n",
      "Processing PDF: shaghayegh2022-splc.pdf (ID: 73)\n",
      "Error extracting text from shaghayegh2022-splc.pdf: name '__file__' is not defined\n",
      "Processing PDF: shu2020.pdf (ID: 59)\n",
      "Error extracting text from shu2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: silva2020.pdf (ID: 60)\n",
      "Error extracting text from silva2020.pdf: name '__file__' is not defined\n",
      "Processing PDF: silva2021-icps.pdf (ID: 61)\n",
      "Error extracting text from silva2021-icps.pdf: name '__file__' is not defined\n",
      "Processing PDF: sree-kumar2021.pdf (ID: 62)\n",
      "Error extracting text from sree-kumar2021.pdf: name '__file__' is not defined\n",
      "Processing PDF: tamim2024-splc.pdf (ID: 74)\n",
      "Error extracting text from tamim2024-splc.pdf: name '__file__' is not defined\n",
      "Processing PDF: temple2019.pdf (ID: 63)\n",
      "Error extracting text from temple2019.pdf: name '__file__' is not defined\n",
      "Processing PDF: tipu2022_cc.pdf (ID: 92)\n",
      "Error extracting text from tipu2022_cc.pdf: name '__file__' is not defined\n",
      "Processing PDF: tërnava2022.pdf (ID: 64)\n",
      "Error extracting text from tërnava2022.pdf: name '__file__' is not defined\n",
      "Processing PDF: valov2020-icpe.pdf (ID: 65)\n",
      "Error extracting text from valov2020-icpe.pdf: name '__file__' is not defined\n",
      "Processing PDF: vázquez-ingelmo2020_cc.pdf (ID: 93)\n",
      "Error extracting text from vázquez-ingelmo2020_cc.pdf: name '__file__' is not defined\n",
      "Processing PDF: xhevahire2023-sac.pdf (ID: 75)\n",
      "Error extracting text from xhevahire2023-sac.pdf: name '__file__' is not defined\n",
      "Processing PDF: yuanjie2023-ase.pdf (ID: 76)\n",
      "Error extracting text from yuanjie2023-ase.pdf: name '__file__' is not defined\n",
      "Processing PDF: yufei2024_jss.pdf (ID: 15)\n",
      "Error extracting text from yufei2024_jss.pdf: name '__file__' is not defined\n",
      "Processing PDF: Švogor2019.pdf (ID: 20)\n",
      "Error extracting text from Švogor2019.pdf: name '__file__' is not defined\n",
      "Database update completed!\n"
     ]
    }
   ],
   "source": [
    "def update_database_with_text_segments(db_path: str):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT id, pdf_name FROM pdfs\")\n",
    "    pdfs = cursor.fetchall()\n",
    "    \n",
    "    all_paths, all_names = find_all_paths_and_names(\"/home/pramos/Documents/AutoSLR/papers_pdf\")\n",
    "    \n",
    "    for pdf_id, pdf_name in pdfs:\n",
    "        print(f\"Processing PDF: {pdf_name} (ID: {pdf_id})\")\n",
    "        \n",
    "        pdf_path = None\n",
    "        for path, name in zip(all_paths, all_names):\n",
    "            if name == pdf_name:\n",
    "                pdf_path = path\n",
    "                break\n",
    "        \n",
    "        if not pdf_path:\n",
    "            print(f\"PDF file not found for: {pdf_name}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            full_text, count = simple_extraction(pdf_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {pdf_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT id, position, section_number, section_title \n",
    "            FROM extracted_text \n",
    "            WHERE pdf_id = ? \n",
    "            ORDER BY position ASC\n",
    "        \"\"\", (pdf_id,))\n",
    "        \n",
    "        sections = cursor.fetchall()\n",
    "        \n",
    "        if not sections:\n",
    "            print(f\"No sections found for PDF: {pdf_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Atualizar o content de cada seção\n",
    "        for i, (section_id, start_pos, section_number, section_title) in enumerate(sections):\n",
    "            try:\n",
    "                if i + 1 < len(sections):\n",
    "                    end_pos = sections[i + 1][1]\n",
    "                else:\n",
    "                    end_pos = len(full_text)\n",
    "                \n",
    "                section_content = full_text[start_pos:end_pos].strip()\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE extracted_text \n",
    "                    SET content = ? \n",
    "                    WHERE id = ?\n",
    "                \"\"\", (section_content, section_id))\n",
    "                \n",
    "                print(f\"  Updated section {section_number}: {section_title[:50]}... \"\n",
    "                      f\"(chars: {start_pos}-{end_pos}, length: {len(section_content)})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing section {section_number} of {pdf_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Completed processing {pdf_name}\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"Database update completed!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "update_database_with_text_segments(\"/home/pramos/Documents/AutoSLR/validations/regex_validation/results/extern_llm-gemini.db\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segment_text(text: str, segment_names: list) -> str:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) local llm tests\n",
    "db_path = \"llm_evaluation.db\"\n",
    "create_llm_tables(db_path, local_llm_models)\n",
    "\n",
    "for model in local_llm_models:\n",
    "    print(f\"Evaluating with model: {model}\")\n",
    "    for path, name in zip(all_file_paths, all_file_names):\n",
    "        \n",
    "        text = extract_text_from_pdf(path)\n",
    "        segmented_text = adfas()\n",
    "\n",
    "        for metric in evaluated_metrics:\n",
    "            prompt_zero_shot = get_prompt_by_metric_zero_shot(metric)\n",
    "            prompt_few_shot = get_prompt_by_metric_few_shot(metric)\n",
    "            \n",
    "            answer_zero_shot = ask_llm(prompt_zero_shot, [segmented_text], model=model)\n",
    "            answer_few_shot = ask_llm(prompt_few_shot, [segmented_text], model=model)\n",
    "            \n",
    "            insert_llm_response(db_path, model, name, \"zero_shot\", metric, answer_zero_shot)\n",
    "            insert_llm_response(db_path, model, name, \"few_shot\", metric, answer_few_shot)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) remote llm tests\n",
    "db_path = \"llm_evaluation.db\"\n",
    "create_llm_tables(db_path, [\"gemini-2.5-flash-preview-05-20\", ]) #make sense use \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
