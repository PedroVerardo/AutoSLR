{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "import fitz\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "from ollama import chat\n",
    "from ollama import Client\n",
    "from ollama import ChatResponse\n",
    "from ollama import generate\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(host='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"num_ctx\": 8192\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>sampling method</th>\n",
       "      <th>systemname</th>\n",
       "      <th>domain</th>\n",
       "      <th>nfp</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset</th>\n",
       "      <th>technique</th>\n",
       "      <th>partition method</th>\n",
       "      <th>evaluation metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alshehri2023</td>\n",
       "      <td>reamostragem SMOTE</td>\n",
       "      <td>Eclipse</td>\n",
       "      <td>system files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[AdaBoost com J48, J48]</td>\n",
       "      <td>Validação cruzada</td>\n",
       "      <td>[Recall , Precision, Medida F ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alves2020</td>\n",
       "      <td>[Coverage-based    , Solver-based, Randomized ...</td>\n",
       "      <td>x264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tempo de codificação e codificação, tamanho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/jualvespereira/ICPE2020</td>\n",
       "      <td>regressão linear múltipla</td>\n",
       "      <td>NI</td>\n",
       "      <td>MRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arcaini2020</td>\n",
       "      <td>Não identifiquei</td>\n",
       "      <td>No identificado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ballesteros2021</td>\n",
       "      <td>NI</td>\n",
       "      <td>[x264, Wget, Berkeley DB Memory, Sensor Networ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Population Size / Archive Size: 400; Number of...</td>\n",
       "      <td>SI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regressão linear</td>\n",
       "      <td>NI</td>\n",
       "      <td>Coverage Metric (CM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chen2022</td>\n",
       "      <td>amostragem adaptativa com d-Simplexed</td>\n",
       "      <td>Spark</td>\n",
       "      <td>Database System</td>\n",
       "      <td>Count,Executor Memory,Executor Threads, Memory...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rede Neural Multicamadas (NN)</td>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>MAPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tipu2022:cc</td>\n",
       "      <td>Random Sampling</td>\n",
       "      <td>[MPI-I/O, SEG-Y I/O]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Number of MPI node, MPI processes per node, S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artificial Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[accuracy, MSE, MAE, MAPE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>valov2020:icpe</td>\n",
       "      <td>amostragem pseudoaleatória</td>\n",
       "      <td>[BZIP2, GZIP, XZ, FLAC, x264]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[árvores de regressão, Regressão linear simple]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MAPE, LOOCV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>vitui2021:ese</td>\n",
       "      <td>Amostragem aleatória</td>\n",
       "      <td>[Open-Src, Entprz. 1, Entprz. 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Random Forest, XGBoost trees, Multi-Layer Per...</td>\n",
       "      <td>[cross-validation, validação cruzada leave-one...</td>\n",
       "      <td>[Median Percentage Deviation, MAPE, MAE, (MSE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>yufei2024:jss</td>\n",
       "      <td>[Random Sampling, Neighborhood Sampling, Input...</td>\n",
       "      <td>[SQLite, BDB-C, BDB-J, LLVM, Sac, Apache, x264...</td>\n",
       "      <td>[Database, Compiler, Web Server, Video Encoder...</td>\n",
       "      <td>[Execution Time, Response Time, Video Encoding...</td>\n",
       "      <td>Execution</td>\n",
       "      <td>https://github.com/RSFIN/RSFIN/tree/master/data</td>\n",
       "      <td>[Artificial Neural Networks (ANN), Deep Learni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Švogor2019</td>\n",
       "      <td>[SCAF com algoritmo genetico, , SCAF usando o ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Component Allocation Framework (SCAF)</td>\n",
       "      <td>NI</td>\n",
       "      <td>Intervalo de confiança</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference                                    sampling method  \\\n",
       "0      Alshehri2023                                 reamostragem SMOTE   \n",
       "1         Alves2020  [Coverage-based    , Solver-based, Randomized ...   \n",
       "2       Arcaini2020                                  Não identifiquei    \n",
       "3   Ballesteros2021                                                 NI   \n",
       "4          Chen2022              amostragem adaptativa com d-Simplexed   \n",
       "..              ...                                                ...   \n",
       "59      tipu2022:cc                                    Random Sampling   \n",
       "60   valov2020:icpe                         amostragem pseudoaleatória   \n",
       "61    vitui2021:ese                               Amostragem aleatória   \n",
       "62    yufei2024:jss  [Random Sampling, Neighborhood Sampling, Input...   \n",
       "63       Švogor2019  [SCAF com algoritmo genetico, , SCAF usando o ...   \n",
       "\n",
       "                                           systemname  \\\n",
       "0                                             Eclipse   \n",
       "1                                                x264   \n",
       "2                                     No identificado   \n",
       "3   [x264, Wget, Berkeley DB Memory, Sensor Networ...   \n",
       "4                                               Spark   \n",
       "..                                                ...   \n",
       "59                               [MPI-I/O, SEG-Y I/O]   \n",
       "60                      [BZIP2, GZIP, XZ, FLAC, x264]   \n",
       "61                   [Open-Src, Entprz. 1, Entprz. 2]   \n",
       "62  [SQLite, BDB-C, BDB-J, LLVM, Sac, Apache, x264...   \n",
       "63                                                NaN   \n",
       "\n",
       "                                               domain  \\\n",
       "0                                        system files   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                     Database System   \n",
       "..                                                ...   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "61                                                NaN   \n",
       "62  [Database, Compiler, Web Server, Video Encoder...   \n",
       "63                                                NaN   \n",
       "\n",
       "                                                  nfp   strategy  \\\n",
       "0                                                 NaN        NaN   \n",
       "1         Tempo de codificação e codificação, tamanho        NaN   \n",
       "2                                                 NaN        NaN   \n",
       "3   Population Size / Archive Size: 400; Number of...         SI   \n",
       "4   Count,Executor Memory,Executor Threads, Memory...        NaN   \n",
       "..                                                ...        ...   \n",
       "59  [Number of MPI node, MPI processes per node, S...        NaN   \n",
       "60                                                NaN        NaN   \n",
       "61                                                NaN        NaN   \n",
       "62  [Execution Time, Response Time, Video Encoding...  Execution   \n",
       "63                                                NaN        NaN   \n",
       "\n",
       "                                            dataset  \\\n",
       "0                                               NaN   \n",
       "1        https://github.com/jualvespereira/ICPE2020   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "..                                              ...   \n",
       "59                                              NaN   \n",
       "60                                              NaN   \n",
       "61                                              NaN   \n",
       "62  https://github.com/RSFIN/RSFIN/tree/master/data   \n",
       "63                                              NaN   \n",
       "\n",
       "                                            technique  \\\n",
       "0                             [AdaBoost com J48, J48]   \n",
       "1                           regressão linear múltipla   \n",
       "2                                                 NaN   \n",
       "3                                    regressão linear   \n",
       "4                       Rede Neural Multicamadas (NN)   \n",
       "..                                                ...   \n",
       "59                         Artificial Neural Networks   \n",
       "60    [árvores de regressão, Regressão linear simple]   \n",
       "61  [Random Forest, XGBoost trees, Multi-Layer Per...   \n",
       "62  [Artificial Neural Networks (ANN), Deep Learni...   \n",
       "63     Software Component Allocation Framework (SCAF)   \n",
       "\n",
       "                                     partition method  \\\n",
       "0                                   Validação cruzada   \n",
       "1                                                  NI   \n",
       "2                                                 NaN   \n",
       "3                                                  NI   \n",
       "4                                           Bootstrap   \n",
       "..                                                ...   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "61  [cross-validation, validação cruzada leave-one...   \n",
       "62                                                NaN   \n",
       "63                                                 NI   \n",
       "\n",
       "                                    evaluation metric  \n",
       "0                     [Recall , Precision, Medida F ]  \n",
       "1                                                 MRE  \n",
       "2                                                 NaN  \n",
       "3                                Coverage Metric (CM)  \n",
       "4                                                MAPE  \n",
       "..                                                ...  \n",
       "59                         [accuracy, MSE, MAE, MAPE]  \n",
       "60                                      [MAPE, LOOCV]  \n",
       "61  [Median Percentage Deviation, MAPE, MAE, (MSE,...  \n",
       "62                                                NaN  \n",
       "63                             Intervalo de confiança  \n",
       "\n",
       "[64 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data-extration.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "rq_sheets = [\"RQ2\", \"RQ3_Systems\", \"RQ4_Learning\", \"RQ5_Partition_Method\", \"RQ5_Metric\"]\n",
    "\n",
    "def extract_citation_key(cite):\n",
    "    if isinstance(cite, str):\n",
    "        match = re.search(r\"\\\\cite{(.+?)}\", cite)\n",
    "        return match.group(1) if match else cite\n",
    "    return cite\n",
    "\n",
    "processed_sheets = {}\n",
    "for sheet in rq_sheets:\n",
    "    df = xls.parse(sheet)\n",
    "    df.columns = [str(col).strip().lower() for col in df.columns]\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('^unnamed')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('^comentário')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('^obs:')]\n",
    "    \n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    if \"reference\" in df.columns:\n",
    "        df[\"reference\"] = df[\"reference\"].apply(extract_citation_key)\n",
    "        \n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col != \"reference\":\n",
    "                agg_dict[col] = lambda x: list(x.dropna().unique()) if len(x.dropna()) > 0 else np.nan\n",
    "        \n",
    "        df = df.groupby(\"reference\", as_index=False).agg(agg_dict)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col != \"reference\":\n",
    "                df[col] = df[col].apply(lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x)\n",
    "\n",
    "    processed_sheets[sheet] = df\n",
    "\n",
    "merged_df = processed_sheets[rq_sheets[0]]\n",
    "for sheet in rq_sheets[1:]:\n",
    "    merged_df = merged_df.merge(processed_sheets[sheet], on=\"reference\", how=\"outer\")\n",
    "\n",
    "merged_df.columns = [col.split('.')[-1] if '.' in col else col for col in merged_df.columns]\n",
    "\n",
    "merged_df.drop(columns=[\"related\", \"ref\", \"cite\"], inplace=True)\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>sampling method</th>\n",
       "      <th>systemname</th>\n",
       "      <th>domain</th>\n",
       "      <th>nfp</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset</th>\n",
       "      <th>technique</th>\n",
       "      <th>partition method</th>\n",
       "      <th>evaluation metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lesoil2024</td>\n",
       "      <td>[K-means, HDBScan, Amostragem aleatória, Submo...</td>\n",
       "      <td>[gcc, ImageMagick, lingeling, nodeJS, poppler,...</td>\n",
       "      <td>[.c programs, images, SAT formulae, .js script...</td>\n",
       "      <td>[size, ctime, exec, size, time, #confl.,#reduc...</td>\n",
       "      <td>EX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OLS Regression, Desicion Tree, Random forest,...</td>\n",
       "      <td>NI</td>\n",
       "      <td>Mean Absolute Percentage Error (MAPE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference                                    sampling method  \\\n",
       "46  lesoil2024  [K-means, HDBScan, Amostragem aleatória, Submo...   \n",
       "\n",
       "                                           systemname  \\\n",
       "46  [gcc, ImageMagick, lingeling, nodeJS, poppler,...   \n",
       "\n",
       "                                               domain  \\\n",
       "46  [.c programs, images, SAT formulae, .js script...   \n",
       "\n",
       "                                                  nfp strategy dataset  \\\n",
       "46  [size, ctime, exec, size, time, #confl.,#reduc...       EX     NaN   \n",
       "\n",
       "                                            technique partition method  \\\n",
       "46  [OLS Regression, Desicion Tree, Random forest,...               NI   \n",
       "\n",
       "                        evaluation metric  \n",
       "46  Mean Absolute Percentage Error (MAPE)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df[\"reference\"] == \"lesoil2024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"reference\"] = merged_df[\"reference\"].str.replace(\":\", \"_\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_message(topic: str, context: str, question: str, some_answer_examples: str,answer_prefix: str, base_text: str, text_example:str, answer_text_example:str) -> str:\n",
    "    message = [{\n",
    "        'role': \"system\",\n",
    "        'content': f\"\"\"You are an expert scientific article analyzer. Your task is to extract specific information \n",
    "        from scientific texts based on provided questions and context. When asked about {topic}, understand that {context}\n",
    "        Examples include: {some_answer_examples}\n",
    "        Your answer should be concise and directly address the question based on the provided text, starting with the phrase:{answer_prefix}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'role': \"user\",\n",
    "        'content': f\"\"\"Please answer the question: {question}, based on the following text: {base_text}\"\"\"\n",
    "    },{\n",
    "        'role': \"assistant\",\n",
    "        'content': f\"\"\"Question: {question}\\n base_text: {text_example}\\nAnswer: {answer_text_example}\n",
    "        \"\"\"\n",
    "    }]\n",
    "\n",
    "    return message\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_list = merged_df[\"reference\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_metrics = [\"sampling method\", \"dataset\", \"technique\", \"partition method\", \"evaluation metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm_models = [\"deepseek-r1:32b\", \"magistral:24b\", \"llama4:latest\"] #testar o llama 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_tables(db_path: str, llm_models: list):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS llm_models (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            model_name TEXT NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS llm_responses (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name_id varchar(510) UNIQUE NOT NULL,\n",
    "            model_id INTEGER,\n",
    "            pdf_name varchar(255),\n",
    "            prompt_technique varchar(255),\n",
    "            text_segmentation_stategy varchar(255),\n",
    "            metric varchar(255),\n",
    "            response TEXT,\n",
    "            FOREIGN KEY (model_id) REFERENCES llm_models(id)\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    for model in llm_models:\n",
    "        cursor.execute('INSERT INTO llm_models (model_name) VALUES (?)', (model,))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_llm_response(db_path: str, model_name: str, pdf_name: str, prompt_technique: str, metric: str, response: str, name_id: str):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('SELECT id FROM llm_models WHERE model_name = ?', (model_name,))\n",
    "    model_id = cursor.fetchone()\n",
    "    if not model_id:\n",
    "        cursor.execute('INSERT INTO llm_models (model_name) VALUES (?)', (model_name,))\n",
    "        conn.commit()\n",
    "        cursor.execute('SELECT id FROM llm_models WHERE model_name = ?', (model_name,))\n",
    "        model_id = cursor.fetchone()\n",
    "    \n",
    "    if model_id:\n",
    "        cursor.execute('''\n",
    "            INSERT INTO llm_responses (model_id, pdf_name, prompt_technique, metric, response, name_id)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (model_id, pdf_name, prompt_technique, metric, response, name_id))\n",
    "        \n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(f\"Model {model_name} not found in the database.\")\n",
    "    \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_and_names(folder_path):\n",
    "    all_paths = []\n",
    "    all_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            all_paths.append(os.path.join(root, file))\n",
    "            all_names.append(file)\n",
    "    return all_paths, all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_extraction(path: str) -> dict[int, str]:\n",
    "        \"\"\"This function extracts text from a PDF file and returns the text along with the number of pages.\n",
    "\n",
    "        Args:\n",
    "            doc (fitz.Document): The PDF document object\n",
    "\n",
    "        Returns:\n",
    "            tuple[str, int]: The text inside the pdf(without any cleaning) and page count\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = \"\"\n",
    "            total_pages = 0\n",
    "            doc = fitz.open(path)\n",
    "            for idx, page in enumerate(doc):\n",
    "                text += f\"<--page_start:{idx+1}-->\"\n",
    "                text +=  page.get_text()\n",
    "                text += f\"<--page_end:{idx+1}-->\"\n",
    "                total_pages += 1\n",
    "            return text, total_pages\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e} in {__file__} \")\n",
    "            return \"\", 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database_with_text_segments(db_path: str):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT id, pdf_name FROM pdfs\")\n",
    "    pdfs = cursor.fetchall()\n",
    "    \n",
    "    all_paths, all_names = find_all_paths_and_names(\"/home/pramos/Documents/AutoSLR/papers_pdf\")\n",
    "    \n",
    "    for pdf_id, pdf_name in pdfs:\n",
    "        print(f\"Processing PDF: {pdf_name} (ID: {pdf_id})\")\n",
    "        \n",
    "        pdf_path = None\n",
    "        for path, name in zip(all_paths, all_names):\n",
    "            if name == pdf_name:\n",
    "                pdf_path = path\n",
    "                break\n",
    "        \n",
    "        if not pdf_path:\n",
    "            print(f\"PDF file not found for: {pdf_name}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            full_text, count = simple_extraction(pdf_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {pdf_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT id, position, section_number, section_title \n",
    "            FROM extracted_text \n",
    "            WHERE pdf_id = ? \n",
    "            ORDER BY position ASC\n",
    "        \"\"\", (pdf_id,))\n",
    "        \n",
    "        sections = cursor.fetchall()\n",
    "        \n",
    "        if not sections:\n",
    "            print(f\"No sections found for PDF: {pdf_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Atualizar o content de cada seção\n",
    "        for i, (section_id, start_pos, section_number, section_title) in enumerate(sections):\n",
    "            try:\n",
    "                if i + 1 < len(sections):\n",
    "                    end_pos = sections[i + 1][1]\n",
    "                else:\n",
    "                    end_pos = len(full_text)\n",
    "                \n",
    "                section_content = full_text[start_pos:end_pos].strip()\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    UPDATE extracted_text \n",
    "                    SET content = ? \n",
    "                    WHERE id = ?\n",
    "                \"\"\", (section_content, section_id))\n",
    "                \n",
    "                print(f\"  Updated section {section_number}: {section_title[:50]}... \"\n",
    "                      f\"(chars: {start_pos}-{end_pos}, length: {len(section_content)})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing section {section_number} of {pdf_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Completed processing {pdf_name}\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"Database update completed!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "update_database_with_text_segments(\"/home/pramos/Documents/AutoSLR/validations/regex_validation/results/extern_llm-gemini.db\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = re.sub(r'^\\d+\\.?\\d*\\.?\\s*', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def calculate_vector_similarity(target_words: List[str], section_titles: List[str]) -> List[Tuple[int, float]]:\n",
    "    processed_targets = [preprocess_text(word) for word in target_words]\n",
    "    processed_titles = [preprocess_text(title) for title in section_titles]\n",
    "    \n",
    "    target_text = ' '.join(processed_targets)\n",
    "    \n",
    "    corpus = [target_text] + processed_titles\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    target_vector = tfidf_matrix[0:1]\n",
    "    title_vectors = tfidf_matrix[1:]\n",
    "    \n",
    "    similarities = cosine_similarity(target_vector, title_vectors)[0]\n",
    "\n",
    "    similarity_scores = [(i, sim) for i, sim in enumerate(similarities)]\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "def extract_words_from_segments(segment_names: List[str]) -> List[str]:\n",
    "    all_words = []\n",
    "    for segment in segment_names:\n",
    "        words = re.findall(r'\\b\\w+\\b', segment.lower())\n",
    "        all_words.extend(words)\n",
    "\n",
    "    unique_words = []\n",
    "    for word in all_words:\n",
    "        if word not in unique_words and len(word) > 2:  # Ignora palavras muito curtas\n",
    "            unique_words.append(word)\n",
    "    \n",
    "    return unique_words\n",
    "\n",
    "def find_segment_text(db_path: str, pdf_name: str, segment_names: List[str], similarity_threshold: float = 0.1) -> str:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "        pdf_result = cursor.fetchone()\n",
    "        \n",
    "        if not pdf_result:\n",
    "            print(f\"PDF '{pdf_name}' não encontrado no banco de dados.\")\n",
    "            return \"\"\n",
    "        \n",
    "        pdf_id = pdf_result[0]\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT section_number, section_title, content, position\n",
    "            FROM extracted_text \n",
    "            WHERE pdf_id = ?\n",
    "            ORDER BY position ASC\n",
    "        \"\"\", (pdf_id,))\n",
    "        \n",
    "        all_sections = cursor.fetchall()\n",
    "        \n",
    "        if not all_sections:\n",
    "            print(f\"Nenhuma seção encontrada no PDF '{pdf_name}'.\")\n",
    "            return \"\"\n",
    "        \n",
    "        section_titles = [section[1] for section in all_sections]\n",
    "        \n",
    "        search_words = extract_words_from_segments(segment_names)\n",
    "        print(f\"Palavras de busca extraídas: {search_words}\")\n",
    "        \n",
    "        similarity_scores = calculate_vector_similarity(search_words, section_titles)\n",
    "        \n",
    "        matched_sections = []\n",
    "        found_sections = []\n",
    "        \n",
    "        for section_idx, similarity in similarity_scores:\n",
    "            if similarity >= similarity_threshold:\n",
    "                section_data = all_sections[section_idx]\n",
    "                section_number, section_title, content, position = section_data\n",
    "                \n",
    "                if content:\n",
    "                    matched_sections.append((section_data, similarity))\n",
    "                    found_sections.append((section_title, similarity))\n",
    "                else:\n",
    "                    print(f\"Aviso: Seção '{section_title}' encontrada mas sem conteúdo.\")\n",
    "        \n",
    "        if not matched_sections:\n",
    "            print(f\"Nenhuma seção encontrada com similaridade >= {similarity_threshold}\")\n",
    "            print(\"Seções disponíveis:\")\n",
    "            for i, title in enumerate(section_titles[:10]):\n",
    "                print(f\"  {i+1}. {title}\")\n",
    "            return \"\"\n",
    "        \n",
    "        matched_sections.sort(key=lambda x: x[0][3])\n",
    "        \n",
    "        combined_content = []\n",
    "        for (section_number, section_title, content, position), similarity in matched_sections:\n",
    "            combined_content.append(f\"=== {section_number} - {section_title} (Similaridade: {similarity:.3f}) ===\\n{content}\")\n",
    "        \n",
    "        print(f\"Seções encontradas no PDF '{pdf_name}':\")\n",
    "        for title, similarity in found_sections:\n",
    "            print(f\"  '{title}' (similaridade: {similarity:.3f})\")\n",
    "        \n",
    "        return \"\\n\\n\".join(combined_content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao buscar segmentos: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def find_best_matching_sections(db_path: str, pdf_name: str, segment_names: List[str], max_sections: int = 3) -> str:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "        pdf_result = cursor.fetchone()\n",
    "        \n",
    "        if not pdf_result:\n",
    "            print(f\"PDF '{pdf_name}' não encontrado no banco de dados.\")\n",
    "            return \"\"\n",
    "        \n",
    "        pdf_id = pdf_result[0]\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT section_number, section_title, content, position\n",
    "            FROM extracted_text \n",
    "            WHERE pdf_id = ?\n",
    "            ORDER BY position ASC\n",
    "        \"\"\", (pdf_id,))\n",
    "        \n",
    "        all_sections = cursor.fetchall()\n",
    "        \n",
    "        if not all_sections:\n",
    "            print(f\"Nenhuma seção encontrada no PDF '{pdf_name}'.\")\n",
    "            return \"\"\n",
    "        \n",
    "        section_titles = [section[1] for section in all_sections]\n",
    "        search_words = extract_words_from_segments(segment_names)\n",
    "        \n",
    "        print(f\"Buscando por: {search_words}\")\n",
    "        \n",
    "        similarity_scores = calculate_vector_similarity(search_words, section_titles)\n",
    "        \n",
    "        top_sections = []\n",
    "        for i in range(min(max_sections, len(similarity_scores))):\n",
    "            section_idx, similarity = similarity_scores[i]\n",
    "            section_data = all_sections[section_idx]\n",
    "            section_number, section_title, content, position = section_data\n",
    "            \n",
    "            if content and similarity > 0: \n",
    "                top_sections.append((section_data, similarity))\n",
    "        \n",
    "        if not top_sections:\n",
    "            print(\"Nenhuma seção relevante encontrada.\")\n",
    "            return \"\"\n",
    "        \n",
    "        top_sections.sort(key=lambda x: x[0][3])\n",
    "        \n",
    "        combined_content = []\n",
    "        print(f\"Top {len(top_sections)} seções mais relevantes:\")\n",
    "        \n",
    "        for (section_number, section_title, content, position), similarity in top_sections:\n",
    "            print(f\"  {section_title} (similaridade: {similarity:.3f})\")\n",
    "            combined_content.append(f\"=== {section_number} - {section_title} ===\\n{content}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(combined_content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao buscar segmentos: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seções encontradas no PDF 'lesoil2024.pdf': ['Introduction']\n",
      "Seções não encontradas: ['Methodology']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'=== 1 - Introduction ===\\n1. Introduction\\nMost modern software systems are widely configurable, featuring\\nmany configuration options that users can set or modify according to\\ntheir needs, for instance, to maximize some performance metrics (e.g.,\\nexecution time, energy consumption). As a software system matures,\\nit diversifies its user base and adds new features to satisfy new needs,\\nincreasing its overall number of options. However, manually quantify-\\ning the individual impact of each option and their interactions quickly\\nbecomes tedious, costly and time-consuming, which reinforces the need\\nto automate how to study and combine these options together. Soft-\\nware reliability can be largely degraded if inappropriate configuration\\noptions are selected or if ageing-related bugs such as configuration-\\ndependent memory leaks remain undetected (Xu et al., 2020).\\nTo address these issues, researchers typically apply machine learning\\n(ML) techniques (Guo et al., 2013; Temple et al., 2017b) to learn\\n✩Editor: Laurence Duchien.\\n∗Corresponding author.\\nE-mail address: mathieu.acher@irisa.fr (M. Acher).\\n1 Videos 1 and 2 are extracted from our dataset (Animation_1080P-5083 and Animation_1080P-646f).\\nperformance models from the selection of configuration options and/or\\nsoftware modules. Conversely, with an accurate performance predic-\\ntive model, it becomes possible to predict the performance of any\\nconfiguration, to find an optimal configuration, or to identify, debug,\\nand reason about influential options of a system (Pereira et al., 2021;\\nJamshidi et al., 2018; Valov et al., 2015; Guo et al., 2013; Nair et al.,\\n2017, 2018b; Siegmund et al., 2015; Sinha et al., 2020; Knüppel et al.,\\n2018). A recent survey (Pereira et al., 2021) synthesized the large\\neffort conducted in the software engineering, software variability, and\\nsoftware product line engineering communities.\\nHowever, the performance variability of a given software system\\nalso obviously depends on its input data (Alourani et al., 2016; Wei\\net al., 2013; Maxiaguine et al., 2004; Zhang et al., 2019; Chen et al.,\\n2021), e.g., a video compressed by a video encoder (Maxiaguine\\net al., 2004) such as x264, a program analysed by a compiler (Chen\\net al., 2021; Ding et al., 2015) such as gcc, a database queried by a\\nhttps://doi.org/10.1016/j.jss.2023.111883\\nReceived 3 March 2023; Received in revised form 17 July 2023; Accepted 21 October 2023\\n<--page_end:1--><--page_start:2-->The Journal of Systems & Software 208 (2024) 111883\\n2\\nL. Lesoil et al.\\nFig. 1. The performance prediction problem: how to predict software performance considering both configurations and inputs?.\\nDBMS (Zhang et al., 2019) such as SQLite. All these kinds of inputs\\nmight interact with the configuration space of the software (Ding et al.,\\n2015; Alves Pereira et al., 2020; Mühlbauer et al., 2023a; Lesoil et al.,\\n2023). For instance, an input video with fixed and high-resolution\\nimages fed to x264 could reach high compression ratios if configuration\\noptions like mbtree are activated. The same option will not be suited\\nfor a low-resolution video depicting an action scene (Maxiaguine et al.,\\n2004) with lots of changes among the different pictures, leading to\\ndifferent performance distributions, as for input videos in Fig. 1.1 The\\ninterplay between input data and configurations has not caught a great\\nattention in the literature (Pereira et al., 2021). It is a threat of practical\\ninterests, since performance models of configurable systems or software\\nproduct lines, can be inaccurate and deprecated whenever a new input\\ndata is processed.\\nRecent works empirically show the significance of inputs (also\\ncalled workloads) when predicting the performance of configurable\\nsystems and software product lines. Alves Pereira et al. (2020) showed\\nthat the performance distribution of 1152 configurations of x264 heav-\\nily depends on the inputs (19 videos) processed. Practically, a good\\nconfiguration can be a bad one depending on the processed video;\\nsome configuration options have varying influence and importance\\ndepending on videos; a performance prediction model can be inaccu-\\nrate if blindly reused whatever the video. Recent empirical results of\\nMühlbauer et al. (2023a) and Lesoil et al. (2023) over different software\\nsystems, configurations and inputs demonstrate that inputs can induce\\nsubstantial performance variations and interact with configuration op-\\ntions, often in non-monotonous ways. As a result, inputs should be\\nconsidered when building performance prediction models to maintain\\nand improve representativeness and reliability.\\nMeasuring all configurations for all possible inputs of a configurable\\nsystem is the most obvious path to resolve the issue. Given a potentially\\ninfinite input space, it is however either too costly and infeasible in\\npractice or impossible. ML techniques are usually employed to measure\\nonly a sample of configurations and then use these configurations’\\nmeasurements to build a performance model capable of predicting the\\nperformance of other configurations (i.e., configurations not measured\\nbefore). However, these measurements are obtained on a specific in-\\nput and are already costly to compute. Systematically repeating this\\nprocess for many inputs would explode the budgets of end-users and\\norganizations. The inputs add a new dimension to the problem of\\nlearning performance models. The combined problem space (configu-\\nration and input dimension) requires substantially more observations\\nand measurements. It further increases the computational cost, since it\\nrequires running configurations over many input samples. The available\\nbudget end-users can dedicate to the measurements of configurations\\nover inputs is limited by construction. Hence, the challenge is to learn an\\naccurate performance model, aware of configurations and inputs, with the\\nlowest budget.\\nSeveral input-aware approaches can be envisioned. The first is to\\nlearn from scratch a performance model, whenever an input is fed to a\\nconfigurable system. Many works target the scenario where users build\\ntheir own performance models for their own inputs and workloads (Guo\\net al., 2013; Siegmund et al., 2015; Pereira et al., 2021; Alves Pereira\\net al., 2020). Unfortunately, users need to measure a sample of config-\\nurations for building a new prediction model each time a new input\\nshould be processed. The computational cost can be prohibitive as\\nit occurs in an online setting (at runtime). There is no reuse of past\\nobservations, knowledge, and performance models. Another second\\napproach, at the opposite of the spectrum, is to pre-train in an offline\\nsetting a set of performance models for different inputs and configura-\\ntions (as, e.g., proposed in Ding et al. (2015)). The upfront cost can be\\nhigh but can pay off since these models are systematically reused when\\na new input comes in. In the example of a configurable video encoder,\\nperformance models could be learned offline and reused each time a\\nnew video (input) is fed. The advantage is that users typically have\\nonly a small budget and cannot make additional measurements at run-\\ntime. The counter-part is that pre-trained models can have forgotten\\nsome inputs and be (much) less accurate than a performance model\\ntrained specifically on an input. At least, it is a hypothesis worth\\nstudying. In between, a third approach is to use both online and offline\\nsettings through transfer learning (Pereira et al., 2021; Jamshidi et al.,\\n2018; Ballesteros and Fuentes, 2021; Martin et al., 2021; Valov et al.,\\n2017). Certain transfer learning methods were originally intended to\\nhandle changes in computing environments, not actual inputs’ changes,\\nnecessitating the development of new techniques that could effectively\\nleverage specific input characteristics (Jamshidi et al., 2017; Valov\\net al., 2017; Jamshidi et al., 2018; Nair et al., 2018a; Valov et al., 2020;\\nLarsson et al., 2021; Iorio et al., 2019). The principle is to adapt existing\\nperformance models (pre-trained in an offline setting over multiple\\ninputs and configurations) thanks to additional measurements gathered\\nover a specific input to process. The hope is to transfer the model with\\nvery few measurements at run time.\\nIn this article, we study and compare the cost-effectiveness of\\nthese three input-aware approaches over a large dataset comprising 8\\n<--page_end:2--><--page_start:3-->The Journal of Systems & Software 208 (2024) 111883\\n3\\nL. Lesoil et al.\\nsoftware systems, hundreds of configurations and inputs, and dozens of\\nperformance properties, spanning a total of 1,941,075 configurations’\\nmeasurements. The distinction between offline and online learning\\nhas not received much attention yet (e.g., most works only apply\\neither ‘‘offline’’ or ‘‘online’’ learning), certainly because of the lack of\\nconsideration of input data that can significantly alter the accuracy\\nof predictive performance models of configurations, as is empirically\\nshown in the rest of the article. We also consider the peculiarities\\nof inputs (i.e., their properties) to guide the transfer or reuse of pre-\\ntrained models. To the best of our knowledge, our work is the first\\ndomain-agnostic empirical evaluation of ML methods addressing the\\ninput-aware performance prediction problem in both online and offline\\nsettings.\\nOur contributions are as follows:\\n1. We perform an extended comparative study of performance model\\ntraining approaches, including supervised learning as well as\\ntransfer learning. We also present their costs and error levels\\nwhen addressing the performance prediction problem;\\n2. We provide guidelines to the user who faces a performance pre-\\ndiction problem and propose a learning-based solution based on\\nher constraints and resources, i.e., based on a trade-off between\\ncosts in offline and online settings.\\n3. We publish the code, the dataset, and the results of this paper\\nonline2 as a basis for future work on predictive performance\\nmodels.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_matching_sections(\"/home/pramos/Documents/AutoSLR/validations/regex_validation/results/extern_llm-gemini.db\", \"lesoil2024.pdf\", [\"Introduction\", \"Methodology\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_local_llm(json_path:str, model_name:str, topic:str, base_text:list[str], prompt_type:str = \"\") -> str:\n",
    "    options = {\n",
    "        \"num_ctx\": 4096\n",
    "    }\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if base_text == []:\n",
    "        return \"\"\n",
    "    \n",
    "    if isinstance(base_text, list):\n",
    "        base_text = \"\\n\\n\".join(base_text)\n",
    "\n",
    "    item = data.get(topic, {})\n",
    "\n",
    "    context = item.get(\"context\", \"\")\n",
    "    question = item.get(\"question\", \"\")\n",
    "    some_answer_examples = item.get(\"some_answer_examples\", \"\")\n",
    "    answer_prefix = item.get(\"answer_prefix\", \"\")\n",
    "    base_text = base_text\n",
    "    text_example = item.get(\"text_example\", \"\")\n",
    "    answer_text_example = item.get(\"answer_text_example\", \"\")\n",
    "    \n",
    "    message = build_message(topic, context, question, some_answer_examples, answer_prefix, base_text, text_example, answer_text_example)\n",
    "    if prompt_type == \"simple\":\n",
    "        message[0]['content'] += f\"\\n\\nPrompt Type: {prompt_type}\"\n",
    "    \n",
    "    answer = chat(model=model_name, messages=message, options=options)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_texts(text1:str, tex2:str) -> str:\n",
    "    if not text1 and not tex2:\n",
    "        err = \"No section found for this paper\"\n",
    "        return \n",
    "    elif text1[:50] == tex2[:50]:\n",
    "        text = text1\n",
    "        err = None\n",
    "    else:\n",
    "        text = join_texts([text1, tex2])\n",
    "        err = None\n",
    "    return err, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_list = merged_df[\"reference\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = [\"simple\", \"complex\", \"one shot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) local llm tests\n",
    "db_path = \"local_llm_evaluation.db\"\n",
    "create_llm_tables(db_path, local_llm_models)\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for model in local_llm_models:\n",
    "    print(f\"Evaluating with model: {model}\")\n",
    "    for name in references_list:\n",
    "        \n",
    "        text_intro = find_best_matching_sections(db_path, name, \"Introduction\", max_sections=1)\n",
    "        text_method = find_best_matching_sections(db_path, name, \"Methodology\", max_sections=1)\n",
    "\n",
    "        err, text = join_texts(text_intro, text_method)\n",
    "        if err:\n",
    "            print(f\"Error for {name}: {err}\")\n",
    "            continue\n",
    "            \n",
    "        for metric in evaluated_metrics:\n",
    "            for prompt_type in prompt_types:\n",
    "                name_id = f\"{name}_{metric}_{model}_{prompt_type}\"\n",
    "                \n",
    "                cursor.execute(\"SELECT 1 FROM llm_responses WHERE name_id = ?\", (name_id,))\n",
    "                exists = cursor.fetchone()\n",
    "                conn.close()\n",
    "                if exists:\n",
    "                    continue\n",
    "                \n",
    "                answer = ask_local_llm(\"metrics.json\", model, metric, text, prompt_type)\n",
    "                \n",
    "                insert_llm_response(db_path, model, name, prompt_type, metric, answer, name_id)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extern_llm_models = [\"gemini-2.5-flash-preview-05-20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) remote llm tests\n",
    "db_path = \"global_llm_evaluation.db\"\n",
    "create_llm_tables(db_path, extern_llm_models)\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for model in extern_llm_models:\n",
    "    print(f\"Evaluating with model: {model}\")\n",
    "    for name in references_list:\n",
    "        \n",
    "        text_intro = find_best_matching_sections(db_path, name, \"Introduction\", max_sections=1)\n",
    "        text_method = find_best_matching_sections(db_path, name, \"Methodology\", max_sections=1)\n",
    "\n",
    "        err, text = join_texts(text_intro, text_method)\n",
    "        if err:\n",
    "            print(f\"Error for {name}: {err}\")\n",
    "            continue\n",
    "            \n",
    "        for metric in evaluated_metrics:\n",
    "            for prompt_type in prompt_types:\n",
    "                name_id = f\"{name}_{metric}_{model}_{prompt_type}\"\n",
    "                \n",
    "                cursor.execute(\"SELECT 1 FROM llm_responses WHERE name_id = ?\", (name_id,))\n",
    "                exists = cursor.fetchone()\n",
    "                conn.close()\n",
    "                if exists:\n",
    "                    continue\n",
    "                \n",
    "                #answer = ask_local_llm(\"metrics.json\", model, metric, text, prompt_type)\n",
    "                #TO-DO: Implement a gemini call\n",
    "                \n",
    "                insert_llm_response(db_path, model, name, prompt_type, metric, answer, name_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
