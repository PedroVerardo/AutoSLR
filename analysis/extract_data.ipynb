{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "from ollama_tools import ask_llm\n",
    "import fitz\n",
    "import os\n",
    "from ollama import chat\n",
    "from ollama import Client\n",
    "from ollama import ChatResponse\n",
    "from ollama import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(host='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>sampling method</th>\n",
       "      <th>systemname</th>\n",
       "      <th>domain</th>\n",
       "      <th>nfp</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset</th>\n",
       "      <th>technique</th>\n",
       "      <th>partition method</th>\n",
       "      <th>evaluation metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alshehri2023</td>\n",
       "      <td>reamostragem SMOTE</td>\n",
       "      <td>Eclipse</td>\n",
       "      <td>system files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[AdaBoost com J48, J48]</td>\n",
       "      <td>Validação cruzada</td>\n",
       "      <td>[Recall , Precision, Medida F ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alves2020</td>\n",
       "      <td>[Coverage-based    , Solver-based, Randomized ...</td>\n",
       "      <td>x264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tempo de codificação e codificação, tamanho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/jualvespereira/ICPE2020</td>\n",
       "      <td>regressão linear múltipla</td>\n",
       "      <td>NI</td>\n",
       "      <td>MRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arcaini2020</td>\n",
       "      <td>Não identifiquei</td>\n",
       "      <td>No identificado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ballesteros2021</td>\n",
       "      <td>NI</td>\n",
       "      <td>[x264, Wget, Berkeley DB Memory, Sensor Networ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Population Size / Archive Size: 400; Number of...</td>\n",
       "      <td>SI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regressão linear</td>\n",
       "      <td>NI</td>\n",
       "      <td>Coverage Metric (CM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chen2022</td>\n",
       "      <td>amostragem adaptativa com d-Simplexed</td>\n",
       "      <td>Spark</td>\n",
       "      <td>Database System</td>\n",
       "      <td>Count,Executor Memory,Executor Threads, Memory...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rede Neural Multicamadas (NN)</td>\n",
       "      <td>Bootstrap</td>\n",
       "      <td>MAPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tipu2022:cc</td>\n",
       "      <td>Random Sampling</td>\n",
       "      <td>[MPI-I/O, SEG-Y I/O]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Number of MPI node, MPI processes per node, S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artificial Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[accuracy, MSE, MAE, MAPE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>valov2020:icpe</td>\n",
       "      <td>amostragem pseudoaleatória</td>\n",
       "      <td>[BZIP2, GZIP, XZ, FLAC, x264]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[árvores de regressão, Regressão linear simple]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MAPE, LOOCV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>vitui2021:ese</td>\n",
       "      <td>Amostragem aleatória</td>\n",
       "      <td>[Open-Src, Entprz. 1, Entprz. 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Random Forest, XGBoost trees, Multi-Layer Per...</td>\n",
       "      <td>[cross-validation, validação cruzada leave-one...</td>\n",
       "      <td>[Median Percentage Deviation, MAPE, MAE, (MSE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>yufei2024:jss</td>\n",
       "      <td>[Random Sampling, Neighborhood Sampling, Input...</td>\n",
       "      <td>[SQLite, BDB-C, BDB-J, LLVM, Sac, Apache, x264...</td>\n",
       "      <td>[Database, Compiler, Web Server, Video Encoder...</td>\n",
       "      <td>[Execution Time, Response Time, Video Encoding...</td>\n",
       "      <td>Execution</td>\n",
       "      <td>https://github.com/RSFIN/RSFIN/tree/master/data</td>\n",
       "      <td>[Artificial Neural Networks (ANN), Deep Learni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Švogor2019</td>\n",
       "      <td>[SCAF com algoritmo genetico, , SCAF usando o ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Component Allocation Framework (SCAF)</td>\n",
       "      <td>NI</td>\n",
       "      <td>Intervalo de confiança</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reference                                    sampling method  \\\n",
       "0      Alshehri2023                                 reamostragem SMOTE   \n",
       "1         Alves2020  [Coverage-based    , Solver-based, Randomized ...   \n",
       "2       Arcaini2020                                  Não identifiquei    \n",
       "3   Ballesteros2021                                                 NI   \n",
       "4          Chen2022              amostragem adaptativa com d-Simplexed   \n",
       "..              ...                                                ...   \n",
       "59      tipu2022:cc                                    Random Sampling   \n",
       "60   valov2020:icpe                         amostragem pseudoaleatória   \n",
       "61    vitui2021:ese                               Amostragem aleatória   \n",
       "62    yufei2024:jss  [Random Sampling, Neighborhood Sampling, Input...   \n",
       "63       Švogor2019  [SCAF com algoritmo genetico, , SCAF usando o ...   \n",
       "\n",
       "                                           systemname  \\\n",
       "0                                             Eclipse   \n",
       "1                                                x264   \n",
       "2                                     No identificado   \n",
       "3   [x264, Wget, Berkeley DB Memory, Sensor Networ...   \n",
       "4                                               Spark   \n",
       "..                                                ...   \n",
       "59                               [MPI-I/O, SEG-Y I/O]   \n",
       "60                      [BZIP2, GZIP, XZ, FLAC, x264]   \n",
       "61                   [Open-Src, Entprz. 1, Entprz. 2]   \n",
       "62  [SQLite, BDB-C, BDB-J, LLVM, Sac, Apache, x264...   \n",
       "63                                                NaN   \n",
       "\n",
       "                                               domain  \\\n",
       "0                                        system files   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                     Database System   \n",
       "..                                                ...   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "61                                                NaN   \n",
       "62  [Database, Compiler, Web Server, Video Encoder...   \n",
       "63                                                NaN   \n",
       "\n",
       "                                                  nfp   strategy  \\\n",
       "0                                                 NaN        NaN   \n",
       "1         Tempo de codificação e codificação, tamanho        NaN   \n",
       "2                                                 NaN        NaN   \n",
       "3   Population Size / Archive Size: 400; Number of...         SI   \n",
       "4   Count,Executor Memory,Executor Threads, Memory...        NaN   \n",
       "..                                                ...        ...   \n",
       "59  [Number of MPI node, MPI processes per node, S...        NaN   \n",
       "60                                                NaN        NaN   \n",
       "61                                                NaN        NaN   \n",
       "62  [Execution Time, Response Time, Video Encoding...  Execution   \n",
       "63                                                NaN        NaN   \n",
       "\n",
       "                                            dataset  \\\n",
       "0                                               NaN   \n",
       "1        https://github.com/jualvespereira/ICPE2020   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "..                                              ...   \n",
       "59                                              NaN   \n",
       "60                                              NaN   \n",
       "61                                              NaN   \n",
       "62  https://github.com/RSFIN/RSFIN/tree/master/data   \n",
       "63                                              NaN   \n",
       "\n",
       "                                            technique  \\\n",
       "0                             [AdaBoost com J48, J48]   \n",
       "1                           regressão linear múltipla   \n",
       "2                                                 NaN   \n",
       "3                                    regressão linear   \n",
       "4                       Rede Neural Multicamadas (NN)   \n",
       "..                                                ...   \n",
       "59                         Artificial Neural Networks   \n",
       "60    [árvores de regressão, Regressão linear simple]   \n",
       "61  [Random Forest, XGBoost trees, Multi-Layer Per...   \n",
       "62  [Artificial Neural Networks (ANN), Deep Learni...   \n",
       "63     Software Component Allocation Framework (SCAF)   \n",
       "\n",
       "                                     partition method  \\\n",
       "0                                   Validação cruzada   \n",
       "1                                                  NI   \n",
       "2                                                 NaN   \n",
       "3                                                  NI   \n",
       "4                                           Bootstrap   \n",
       "..                                                ...   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "61  [cross-validation, validação cruzada leave-one...   \n",
       "62                                                NaN   \n",
       "63                                                 NI   \n",
       "\n",
       "                                    evaluation metric  \n",
       "0                     [Recall , Precision, Medida F ]  \n",
       "1                                                 MRE  \n",
       "2                                                 NaN  \n",
       "3                                Coverage Metric (CM)  \n",
       "4                                                MAPE  \n",
       "..                                                ...  \n",
       "59                         [accuracy, MSE, MAE, MAPE]  \n",
       "60                                      [MAPE, LOOCV]  \n",
       "61  [Median Percentage Deviation, MAPE, MAE, (MSE,...  \n",
       "62                                                NaN  \n",
       "63                             Intervalo de confiança  \n",
       "\n",
       "[64 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data-extration.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "rq_sheets = [\"RQ2\", \"RQ3_Systems\", \"RQ4_Learning\", \"RQ5_Partition_Method\", \"RQ5_Metric\"]\n",
    "\n",
    "def extract_citation_key(cite):\n",
    "    if isinstance(cite, str):\n",
    "        match = re.search(r\"\\\\cite{(.+?)}\", cite)\n",
    "        return match.group(1) if match else cite\n",
    "    return cite\n",
    "\n",
    "processed_sheets = {}\n",
    "for sheet in rq_sheets:\n",
    "    df = xls.parse(sheet)\n",
    "    df.columns = [str(col).strip().lower() for col in df.columns]\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('^unnamed')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('^comentário')]\n",
    "    df = df.loc[:, ~df.columns.str.contains('^obs:')]\n",
    "    \n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    if \"reference\" in df.columns:\n",
    "        df[\"reference\"] = df[\"reference\"].apply(extract_citation_key)\n",
    "        \n",
    "        agg_dict = {}\n",
    "        for col in df.columns:\n",
    "            if col != \"reference\":\n",
    "                agg_dict[col] = lambda x: list(x.dropna().unique()) if len(x.dropna()) > 0 else np.nan\n",
    "        \n",
    "        df = df.groupby(\"reference\", as_index=False).agg(agg_dict)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col != \"reference\":\n",
    "                df[col] = df[col].apply(lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x)\n",
    "\n",
    "    processed_sheets[sheet] = df\n",
    "\n",
    "merged_df = processed_sheets[rq_sheets[0]]\n",
    "for sheet in rq_sheets[1:]:\n",
    "    merged_df = merged_df.merge(processed_sheets[sheet], on=\"reference\", how=\"outer\")\n",
    "\n",
    "merged_df.columns = [col.split('.')[-1] if '.' in col else col for col in merged_df.columns]\n",
    "\n",
    "merged_df.drop(columns=[\"related\", \"ref\", \"cite\"], inplace=True)\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>sampling method</th>\n",
       "      <th>systemname</th>\n",
       "      <th>domain</th>\n",
       "      <th>nfp</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset</th>\n",
       "      <th>technique</th>\n",
       "      <th>partition method</th>\n",
       "      <th>evaluation metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lesoil2024</td>\n",
       "      <td>[K-means, HDBScan, Amostragem aleatória, Submo...</td>\n",
       "      <td>[gcc, ImageMagick, lingeling, nodeJS, poppler,...</td>\n",
       "      <td>[.c programs, images, SAT formulae, .js script...</td>\n",
       "      <td>[size, ctime, exec, size, time, #confl.,#reduc...</td>\n",
       "      <td>EX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OLS Regression, Desicion Tree, Random forest,...</td>\n",
       "      <td>NI</td>\n",
       "      <td>Mean Absolute Percentage Error (MAPE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reference                                    sampling method  \\\n",
       "46  lesoil2024  [K-means, HDBScan, Amostragem aleatória, Submo...   \n",
       "\n",
       "                                           systemname  \\\n",
       "46  [gcc, ImageMagick, lingeling, nodeJS, poppler,...   \n",
       "\n",
       "                                               domain  \\\n",
       "46  [.c programs, images, SAT formulae, .js script...   \n",
       "\n",
       "                                                  nfp strategy dataset  \\\n",
       "46  [size, ctime, exec, size, time, #confl.,#reduc...       EX     NaN   \n",
       "\n",
       "                                            technique partition method  \\\n",
       "46  [OLS Regression, Desicion Tree, Random forest,...               NI   \n",
       "\n",
       "                        evaluation metric  \n",
       "46  Mean Absolute Percentage Error (MAPE)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df[\"reference\"] == \"lesoil2024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"reference\"] = merged_df[\"reference\"].str.replace(\":\", \"_\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages=[\n",
    "#   {\n",
    "#     'role': 'user',\n",
    "#     'content': 'Why is the sky blue?',\n",
    "#   },\n",
    "# ])\n",
    "\n",
    "\n",
    "def build_message(topic: str, context: str, question: str, some_answer_examples: str,answer_prefix: str, base_text: str, text_example:str, answer_text_example:str, model: str) -> str:\n",
    "    message = [{\n",
    "        'role': \"system\",\n",
    "        'content': f\"\"\"You are an expert scientific article analyzer. Your task is to extract specific information \n",
    "        from scientific texts based on provided questions and context. When asked about {topic}, understand that {context}\n",
    "        Examples include: {some_answer_examples}\n",
    "        Your answer should be concise and directly address the question based on the provided text, starting with the phrase:{answer_prefix}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'role': \"user\",\n",
    "        'content': f\"\"\"Please answer the question: {question}, based on the following text: {base_text}\"\"\"\n",
    "    },{\n",
    "        'role': \"assistant\",\n",
    "        'content': f\"\"\"Question: {question}\\n base_text: {text_example}\\nAnswer: {answer_text_example}\n",
    "        \"\"\"\n",
    "    }]\n",
    "\n",
    "    return message\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prompt_by_metric_zero_shot(metric: str) -> str:\n",
    "#     match(metric):\n",
    "#         case \"sampling method\":\n",
    "#             return \"\"\"\n",
    "#             Q: What sampling method is used in the paper?\n",
    "#             A: The sampling method used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case \"dataset\":\n",
    "#             return \"\"\"\n",
    "#             Q: What dataset is used in the paper?\n",
    "#             A: The dataset used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case \"technique\": # ver nome do metodo\n",
    "#             return \"\"\"\n",
    "#             Q: What learning method is used in the paper?\n",
    "#             A: The learning method used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case \"partition method\":\n",
    "#             return \"\"\"\n",
    "#             Q: What partition method is used in the paper?\n",
    "#             A: The partition method used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case \"evaluation metric\":\n",
    "#             return \"\"\"\n",
    "#             Q: What evaluation metric is used in the paper?\n",
    "#             A: The evaluation metric used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case _:\n",
    "#             raise ValueError(f\"Unknown metric: {metric}\")\n",
    "        \n",
    "# def get_prompt_by_metric_with_context(metric: str) -> str:\n",
    "#     match(metric):\n",
    "#         case \"sampling method\":\n",
    "#             return \"\"\"\n",
    "#             Context: sampling methods are used to select a representative subset from a dataset. They are often used to reduce the size of the dataset while maintaining its diversity and characteristics.\n",
    "#             Examples: Randon sampling, Stratified sampling, Systematic sampling, Cluster sampling, Convenience sampling, Purposive sampling, Snowball sampling and etc... .\n",
    "#             Q: What sampling method is used in the paper?\n",
    "#             A: The sampling method used in the paper are/is:\n",
    "#             \"\"\"\n",
    "#         case \"dataset\":\n",
    "#             return \"\"\"\n",
    "#             Context: datasets are collections of data used for training and evaluating machine learning models. They can vary in size, type, and structure.\n",
    "#             Types of datasets: Image datasets, Text datasets, Audio datasets, Video datasets, Tabular datasets and etc... .\n",
    "#             Formats of datasets: CSV, JSON, XML, Parquet, HDF5 and etc... .\n",
    "#             Q: What dataset is used in the paper?\n",
    "#             A: The dataset used in the paper are:\n",
    "#             \"\"\"\n",
    "#         case \"technique\":\n",
    "#             return \"\"\"\n",
    "#             Context: techniques refer to the methods or approaches used in the Machine Learning field to solve specific problems or tasks. They are normally categorized in supervised learning (classification, regression), unsupervised learning (clustering, dimensionality reduction).\n",
    "#             Other special categorie is Deep Learning (Convolutional Neural Networks, Recurrent Neural Networks, Transformers, Generative Adversarial Networks and etc... ).\n",
    "#             Examples of techniques: Decision Trees, Support Vector Machines, Neural Networks, k-Nearest Neighbors, Random Forests, Gradient Boosting Machines and etc... .\n",
    "#             Q: What technique is used in the paper?\n",
    "#             A: The technique used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case \"partition method\":\n",
    "#             return \"\"\"\n",
    "#             Context: partition methods are used to divide a dataset into subsets for training, validation, and testing. They help in evaluating the performance of machine learning models by ensuring that the model is tested on unseen data.\n",
    "#             Examples of partition methods: Holdout method, k-Fold Cross-Validation, Stratified k-Fold Cross-Validation, Leave-One-Out Cross-Validation (LOOCV), Time Series Split and etc... .\n",
    "#             Q: What partition method is used in the paper?\n",
    "#             A: The partition method used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case \"evaluation metric\":\n",
    "#             return \"\"\"\n",
    "#             Context: evaluation metrics are used to assess the performance of machine learning models. They provide a quantitative measure of how well a model performs on a given task.\n",
    "#             Example: accuracy, precision, recall, F1-score, ROC-AUC, mean absolute error(MAE), and mean squared error(MSE).\n",
    "#             Q: What evaluation metric is used in the paper?\n",
    "#             A: The evaluation metric used in the paper is:\n",
    "#             \"\"\"\n",
    "#         case _:\n",
    "#             raise ValueError(f\"Unknown metric: {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_list = merged_df[\"reference\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_metrics = [\"sampling method\", \"dataset\", \"technique\", \"partition method\", \"evaluation metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_citation_key(cite):\n",
    "    match = re.search(r\"\\\\cite{(.+?)}\", cite)\n",
    "    return match.group(1) if match else cite\n",
    "\n",
    "df[\"reference\"] = df[\"reference\"].apply(extract_citation_key)\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ref = row[\"reference\"]\n",
    "    result_dict[ref] = {\n",
    "        \"sampling method\": row[\"sampling method\"],\n",
    "        \"dataset\": row[\"dataset\"],\n",
    "        \"technique\": row[\"technique\"],\n",
    "        \"partition method\": row[\"partition method\"],\n",
    "        \"evaluation metric\": row[\"evaluation metric\"]\n",
    "    }\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm_models = [\"deepseek-r1:32b\", \"magistral:24b\", \"mistral-nemo:12b\"] #testar o llama 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_tables(db_path: str, llm_models: list):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS llm_models (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            model_name TEXT NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS llm_responses (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            model_id INTEGER,\n",
    "            pdf_name varchar(255),\n",
    "            prompt_technique varchar(255),\n",
    "            text_segmentation_stategy varchar(255),\n",
    "            metric varchar(255),\n",
    "            response TEXT,\n",
    "            FOREIGN KEY (model_id) REFERENCES llm_models(id)\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    for model in llm_models:\n",
    "        cursor.execute('INSERT INTO llm_models (model_name) VALUES (?)', (model,))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_llm_response(db_path: str, model_name: str, pdf_name: str, prompt_technique: str, metric: str, response: str, text_segmentation_stategy: str):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('SELECT id FROM llm_models WHERE model_name = ?', (model_name,))\n",
    "    model_id = cursor.fetchone()\n",
    "    if not model_id:\n",
    "        cursor.execute('INSERT INTO llm_models (model_name) VALUES (?)', (model_name,))\n",
    "        conn.commit()\n",
    "        cursor.execute('SELECT id FROM llm_models WHERE model_name = ?', (model_name,))\n",
    "        model_id = cursor.fetchone()\n",
    "    \n",
    "    if model_id:\n",
    "        cursor.execute('''\n",
    "            INSERT INTO llm_responses (model_id, pdf_name, prompt_technique, metric, response, text_segmentation_stategy)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (model_id, pdf_name, prompt_technique, metric, response, text_segmentation_stategy))\n",
    "        \n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(f\"Model {model_name} not found in the database.\")\n",
    "    \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_and_names(folder_path):\n",
    "    all_paths = []\n",
    "    all_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            all_paths.append(os.path.join(root, file))\n",
    "            all_names.append(file)\n",
    "    return all_paths, all_names\n",
    "\n",
    "all_file_paths, all_file_names = find_all_paths_and_names(\"/home/pramos/Documents/AutoSLR/papers_pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"PDF file {pdf_path} does not exist. Skipping.\")\n",
    "        \n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "\n",
    "    doc.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segment_text(text: str, segment_names: list) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) local llm tests\n",
    "db_path = \"llm_evaluation.db\"\n",
    "create_llm_tables(db_path, local_llm_models)\n",
    "\n",
    "for model in local_llm_models:\n",
    "    print(f\"Evaluating with model: {model}\")\n",
    "    for path, name in zip(all_file_paths, all_file_names):\n",
    "        \n",
    "        text = extract_text_from_pdf(path)\n",
    "        segmented_text = adfas()\n",
    "\n",
    "        for metric in evaluated_metrics:\n",
    "            prompt_zero_shot = get_prompt_by_metric_zero_shot(metric)\n",
    "            prompt_few_shot = get_prompt_by_metric_few_shot(metric)\n",
    "            \n",
    "            answer_zero_shot = ask_llm(prompt_zero_shot, [segmented_text], model=model)\n",
    "            answer_few_shot = ask_llm(prompt_few_shot, [segmented_text], model=model)\n",
    "            \n",
    "            insert_llm_response(db_path, model, name, \"zero_shot\", metric, answer_zero_shot)\n",
    "            insert_llm_response(db_path, model, name, \"few_shot\", metric, answer_few_shot)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) remote llm tests\n",
    "db_path = \"llm_evaluation.db\"\n",
    "create_llm_tables(db_path, [\"gemini-2.5-flash-preview-05-20\", ]) #make sense use \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
