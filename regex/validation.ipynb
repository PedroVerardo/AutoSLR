{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "operator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdf_handler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFHandler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/regex/pdf_handler.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_converter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocumentConverter\n\u001b[1;32m     15\u001b[0m OLLAMA_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:11434\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mConsiderations:\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m- The regex could not be super generic\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m- probably do not have ponctuation in the section title\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/docling/document_converter.py:48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasePipeline\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimple_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimplePipeline\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandard_pdf_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardPdfPipeline\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunkify\n\u001b[1;32m     51\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:22\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_picture_classifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     DocumentPictureClassifier,\n\u001b[1;32m     19\u001b[0m     DocumentPictureClassifierOptions,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactories\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_ocr_factory, get_picture_description_factory\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayoutModel\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpage_assemble_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PageAssembleModel, PageAssembleOptions\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpage_preprocessing_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     PagePreprocessingModel,\n\u001b[1;32m     26\u001b[0m     PagePreprocessingOptions,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/docling/models/layout_model.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocItemLabel\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling_ibm_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayoutmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout_predictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayoutPredictor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorOptions\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDetrForObjectDetection, RTDetrImageProcessor\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/torchvision/_meta_registrations.py:164\u001b[0m\n\u001b[1;32m    153\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(\n\u001b[1;32m    154\u001b[0m         grad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m rois\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m         ),\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchvision::nms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should have 4 elements in dimension 1, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/torch/library.py:828\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[0;32m--> 828\u001b[0m \u001b[43muse_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/torch/library.py:198\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[0;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m--> 198\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m~/Documentos/AutoSLR/venv/lib/python3.10/site-packages/torch/_library/fake_impl.py:31\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[0;34m(self, func, source)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel_for_dispatch_key(\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompositeImplicitAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m ):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "from pdf_handler import PDFHandler\n",
    "\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from docling.document_converter import DocumentConverter\n",
    "from dotenv import load_dotenv\n",
    "from Section import SectionInfo\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_and_names(folder_path):\n",
    "    all_paths = []\n",
    "    all_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            all_paths.append(os.path.join(root, file))\n",
    "            all_names.append(file)\n",
    "    return all_paths, all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to your folder with PDF files\n",
    "all_file_paths, all_file_names = find_all_paths_and_names(\"/home/pramos/Documents/AutoSLR/papers_pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regex_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) generic regex for all pdfs\n",
    "db_name = \"results/generic_regex.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    \n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "\n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "    try:\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[\"generic_section_title\"])\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) tagged regex extraction for all pdfs\n",
    "db_name = \"results/tagged_regex.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "PDFHandler.create_tables(conn)\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        # print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    \n",
    "    text, page_count, size_mode = PDFHandler.tagged_text_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "\n",
    "    try:\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[\"generic_section_title\"])\n",
    "        sections = [section for section in sections if getattr(section, 'is_bold', False) or getattr(section, 'size', 0) >= size_mode]\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 matches:\n",
      "Found 1 matches:\n",
      "Found 11 matches:\n",
      "Found 6 matches:\n",
      "Found 12 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 27 matches:\n",
      "Found 9 matches:\n",
      "Found 20 matches:\n",
      "Found 5 matches:\n",
      "Found 9 matches:\n",
      "Found 15 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Found 62 matches:\n",
      "Found 22 matches:\n",
      "Found 4 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 10 matches:\n",
      "Found 45 matches:\n",
      "Found 10 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 10 matches:\n",
      "Found 5 matches:\n",
      "Found 10 matches:\n",
      "Found 8 matches:\n",
      "Found 9 matches:\n",
      "Found 13 matches:\n",
      "Found 10 matches:\n",
      "Found 8 matches:\n",
      "Found 8 matches:\n",
      "Found 12 matches:\n",
      "Found 10 matches:\n",
      "Found 12 matches:\n",
      "Found 9 matches:\n",
      "Found 5 matches:\n",
      "Found 22 matches:\n",
      "Found 5 matches:\n",
      "Found 4 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 6 matches:\n",
      "Found 55 matches:\n",
      "Found 36 matches:\n",
      "Found 19 matches:\n",
      "Found 16 matches:\n",
      "Found 14 matches:\n",
      "Found 9 matches:\n",
      "Found 12 matches:\n",
      "Found 6 matches:\n",
      "Found 3 matches:\n",
      "Found 26 matches:\n",
      "Found 8 matches:\n",
      "Found 20 matches:\n",
      "Found 13 matches:\n",
      "Found 6 matches:\n",
      "Found 5 matches:\n",
      "Found 14 matches:\n",
      "Found 9 matches:\n",
      "Found 48 matches:\n",
      "Found 8 matches:\n",
      "Found 10 matches:\n",
      "Found 10 matches:\n",
      "Found 7 matches:\n",
      "Found 5 matches:\n",
      "Found 27 matches:\n",
      "Found 17 matches:\n",
      "Found 9 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Found 6 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 45 matches:\n",
      "Found 11 matches:\n",
      "Found 14 matches:\n",
      "Found 7 matches:\n",
      "Found 7 matches:\n",
      "Error processing Arcaini2020.pdf: Error binding parameter 1 - probably unsupported type.\n",
      "Found 10 matches:\n",
      "Found 9 matches:\n",
      "Found 6 matches:\n",
      "Found 8 matches:\n",
      "Found 7 matches:\n",
      "Found 6 matches:\n",
      "Found 3 matches:\n",
      "Found 7 matches:\n",
      "Found 14 matches:\n",
      "Found 15 matches:\n",
      "Found 7 matches:\n",
      "Found 8 matches:\n"
     ]
    }
   ],
   "source": [
    "#3) specific regex extraction for all pdfs\n",
    "db_name = \"results/specific_regex.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "PDFHandler.create_tables(conn)\n",
    "\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    \n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "\n",
    "    try:\n",
    "        section_type = df[df['pdf_name'] == name[:-4]]['section_type'].values[0]\n",
    "        # print(f\"Processing {name} with section type: {section_type}\")\n",
    "        if section_type not in PDFHandler.regex_patterns:\n",
    "            # print(f\"Section type {section_type} not found in regex patterns.\")\n",
    "            continue\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[section_type],  debug=True)\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) voting policy for all pdfs\n",
    "db_name = \"results/voting_policy.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "PDFHandler.create_tables(conn)\n",
    "\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    \n",
    "    text, page_count, size_mode = PDFHandler.tagged_text_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "\n",
    "    try:\n",
    "        section_type = df[df['pdf_name'] == name[:-4]]['section_type'].values[0]\n",
    "        if section_type not in PDFHandler.regex_patterns:\n",
    "            # print(f\"Section type {section_type} not found in regex patterns.\")\n",
    "            continue\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[section_type], debug=True)\n",
    "        sections = PDFHandler.voting_policy(sections, size_mode)\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment2prompt(sections: list) -> str:\n",
    "   prompt = \"\"\"Analyze the following potential section titles extracted by regex pattern matching. Some may be actual section headers while others could be false positives (table entries, references, footnotes, etc.).\n",
    "\n",
    "Please identify which ones are most likely to be legitimate section titles for an academic paper or document:\n",
    "\n",
    "\"\"\"\n",
    "   \n",
    "   for idx, section in enumerate(sections):\n",
    "       prompt += f\"({idx}) {section.section_number}. {section.section_title}\\n\"\n",
    "   \n",
    "   prompt += \"\"\"\n",
    "            EVALUATION CRITERIA:\n",
    "            - Look for typical section patterns (Introduction, Methods, Results, Discussion, Conclusion, etc.)\n",
    "            - Consider formatting consistency and logical flow\n",
    "            - Exclude obvious false positives like:\n",
    "            - Table captions or figure titles\n",
    "            - Reference entries or citations\n",
    "            - Page headers/footers\n",
    "            - Numbered lists within paragraphs\n",
    "            - Partial sentences or fragments\n",
    "\n",
    "            Please respond with a JSON object containing the indices of legitimate section titles:\n",
    "\n",
    "            {\n",
    "            \"selected_sections\": [0, 2, 5, 8]\n",
    "            }\n",
    "\n",
    "            Response:\"\"\"\n",
    "   \n",
    "   return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_sections(response_text: str) -> list:\n",
    "    # Procura por padrão JSON no texto\n",
    "    json_pattern = r'\\{[^}]*\"selected_sections\"[^}]*\\[[^\\]]*\\][^}]*\\}'\n",
    "    match = re.search(json_pattern, response_text)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            json_data = json.loads(match.group())\n",
    "            return json_data.get(\"selected_sections\", [])\n",
    "        except json.JSONDecodeError:\n",
    "            return []\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "def ask_llm(prompt, context: list[str] = [], model=\"deepseek-r1:1.5b\"):\n",
    "    try:\n",
    "\n",
    "        if isinstance(prompt, list):\n",
    "            prompt = \"\\n\".join(str(item) for item in prompt)\n",
    "\n",
    "        if isinstance(context, list):\n",
    "            context = \"\\n\".join(str(item) for item in context)\n",
    "\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            f'{OLLAMA_URL}/api/generate',\n",
    "            json=data,\n",
    "            timeout=10,\n",
    "            stream=False\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for line in response.text.splitlines():\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    json_response = json.loads(line)\n",
    "                    if 'response' in json_response:\n",
    "                        full_response += json_response['response']\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        return full_response\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return \"Error: Cannot connect to Ollama server\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: Request failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid sections found for Arcaini2020.pdf using LLM.\n",
      "No valid sections found for Švogor2019.pdf using LLM.\n",
      "No valid sections found for Ha2019-icse.pdf using LLM.\n",
      "No valid sections found for Liu2022.pdf using LLM.\n",
      "No valid sections found for Temple2021.pdf using LLM.\n",
      "No valid sections found for Weber2021.pdf using LLM.\n",
      "No valid sections found for schmid2022.pdf using LLM.\n",
      "No valid sections found for hugo2021-tse.pdf using LLM.\n",
      "No valid sections found for shaghayegh2022-splc.pdf using LLM.\n",
      "No valid sections found for liang2024cc.pdf using LLM.\n"
     ]
    }
   ],
   "source": [
    "#5) Local llms to analyze the generic regex\n",
    "\n",
    "model = \"llama3:8b\"\n",
    "db_name = f\"results/local_llms{model}.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    \n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "\n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    text = PDFHandler.default_pdf_cleaning(text)\n",
    "    try:\n",
    "        sections = PDFHandler.find_pattern_in_text(text, PDFHandler.regex_patterns[\"generic_section_title\"])\n",
    "        prompt = segment2prompt(sections)\n",
    "        answare = ask_llm(prompt, model=\"llama3:8b\")\n",
    "        if answare.startswith(\"Error:\") or answare == \"\":\n",
    "            print(f\"LLM error for {name}: {answare}\")\n",
    "            continue\n",
    "        position_list = extract_selected_sections(answare)\n",
    "        if not position_list:\n",
    "            print(f\"No valid sections found for {name} using LLM.\")\n",
    "            continue\n",
    "        sections = [sections[i] for i in position_list if i < len(sections)]\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf_to_gemini(pdf_path):\n",
    "        \"\"\"Faz upload do PDF para o Gemini\"\"\"\n",
    "        try:\n",
    "            # Upload do arquivo para o Gemini\n",
    "            uploaded_file = genai.upload_file(pdf_path)\n",
    "            print(f\"Arquivo enviado: {uploaded_file.name}\")\n",
    "            \n",
    "            # Aguarda o processamento do arquivo\n",
    "            while uploaded_file.state.name == \"PROCESSING\":\n",
    "                print(\"Processando arquivo...\")\n",
    "                time.sleep(2)\n",
    "                uploaded_file = genai.get_file(uploaded_file.name)\n",
    "            \n",
    "            if uploaded_file.state.name == \"FAILED\":\n",
    "                raise ValueError(\"Falha no processamento do arquivo\")\n",
    "                \n",
    "            return uploaded_file\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no upload do PDF: {e}\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    clean_text = response_text.strip()\n",
    "    \n",
    "    clean_text = re.sub(r'^```(?:json)?\\s*', '', clean_text, flags=re.MULTILINE)\n",
    "    clean_text = re.sub(r'\\s*```\\s*$', '', clean_text, flags=re.MULTILINE)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(clean_text.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
    "        match = re.search(json_pattern, clean_text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group())\n",
    "        raise ValueError(\"No valid JSON found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing amraoui2022_splc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/g4khr18gexv0\n",
      "Successfully processed amraoui2022_splc.pdf with 10 sections\n",
      "Processing cheng2023_tse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/1jwxi090k8ux\n",
      "Successfully processed cheng2023_tse.pdf with 8 sections\n",
      "Processing dorn2020_vamos.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/92sd168k11wm\n",
      "Successfully processed dorn2020_vamos.pdf with 10 sections\n",
      "Processing friesel2022_icse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/rbuhzjq5jrp8\n",
      "Successfully processed friesel2022_icse.pdf with 12 sections\n",
      "Processing gong2022_msr.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/wfuvbzkti8ab\n",
      "Successfully processed gong2022_msr.pdf with 11 sections\n",
      "Processing gong2023_fse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/5fw5eq94zql0\n",
      "Successfully processed gong2023_fse.pdf with 13 sections\n",
      "Processing isaev2023_hpcc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/3bu01v78pn1k\n",
      "Successfully processed isaev2023_hpcc.pdf with 11 sections\n",
      "Processing kolesnikov2019_emse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/84skfz3x2zq7\n",
      "Successfully processed kolesnikov2019_emse.pdf with 11 sections\n",
      "Processing kolesnikov2019_ssm.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/gobxnmz4i9eg\n",
      "Successfully processed kolesnikov2019_ssm.pdf with 8 sections\n",
      "Processing lesoil2022_vamos.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/egpyoz8t3olp\n",
      "Successfully processed lesoil2022_vamos.pdf with 8 sections\n",
      "Processing magrin2022_twc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/3w821u1nndaa\n",
      "Successfully processed magrin2022_twc.pdf with 9 sections\n",
      "Processing muhlbauer2023_icse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/rjksjt5d718w\n",
      "Successfully processed muhlbauer2023_icse.pdf with 11 sections\n",
      "Processing peeters2021_ida.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/ulsvud5wsdae\n",
      "Successfully processed peeters2021_ida.pdf with 8 sections\n",
      "Processing ros2020_emse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/skgewby1yo3e\n",
      "Successfully processed ros2020_emse.pdf with 14 sections\n",
      "Processing yufei2024_jss.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/bk0tqd8n9mn9\n",
      "Successfully processed yufei2024_jss.pdf with 11 sections\n",
      "Processing Arcaini2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/cl23ix80bbkq\n",
      "Successfully processed Arcaini2020.pdf with 11 sections\n",
      "Processing H. Martin2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/evh5twvfjgel\n",
      "Successfully processed H. Martin2022.pdf with 10 sections\n",
      "Processing lesoil2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/g8ls9v9k20ds\n",
      "Successfully processed lesoil2023.pdf with 13 sections\n",
      "Processing lesoil2024.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/tkaad1j4xpht\n",
      "Successfully processed lesoil2024.pdf with 13 sections\n",
      "Processing Švogor2019.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/ot14zaeopkil\n",
      "Successfully processed Švogor2019.pdf with 9 sections\n",
      "Processing Alshehri2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/ctd2prshn091\n",
      "Successfully processed Alshehri2020.pdf with 8 sections\n",
      "Processing Chen2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/4tgwzeiolwaj\n",
      "Successfully processed Chen2022.pdf with 11 sections\n",
      "Processing Damasceno2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/s88b3weheecm\n",
      "Successfully processed Damasceno2021.pdf with 11 sections\n",
      "Processing Gao2021-ICSE.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/2mg5gapwkhmm\n",
      "Successfully processed Gao2021-ICSE.pdf with 1 sections\n",
      "Processing García2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/j5m4ja9n2epp\n",
      "Successfully processed García2021.pdf with 8 sections\n",
      "Processing Ha-2019ICSME.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/d6v7wfuslsqs\n",
      "Successfully processed Ha-2019ICSME.pdf with 10 sections\n",
      "Processing Ha2019-icse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/h8e613ta4vvw\n",
      "Successfully processed Ha2019-icse.pdf with 8 sections\n",
      "Processing Iorio2019.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/dqylrye6822s\n",
      "Successfully processed Iorio2019.pdf with 8 sections\n",
      "Processing Iqbal2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/d7xjwkf8lh0z\n",
      "Successfully processed Iqbal2022.pdf with 15 sections\n",
      "Processing Iqbal2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/4jnwhh1kkr8r\n",
      "Successfully processed Iqbal2023.pdf with 12 sections\n",
      "Processing Kaltenecker2019.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/2gldaehz2hay\n",
      "Successfully processed Kaltenecker2019.pdf with 9 sections\n",
      "Processing Krishna2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/xwai02p8ig82\n",
      "Successfully processed Krishna2021.pdf with 13 sections\n",
      "Processing Kumara2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/bw0svokbz0l8\n",
      "Error processing Kumara2023.pdf with Gemini: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "Processing Liu2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/1eb0cl71brm8\n",
      "Successfully processed Liu2022.pdf with 9 sections\n",
      "Processing Muhlbauer2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/ar2jihjz05y6\n",
      "Successfully processed Muhlbauer2020.pdf with 11 sections\n",
      "Processing Muhlbauer2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/lezx8jmvh4tw\n",
      "Successfully processed Muhlbauer2023.pdf with 11 sections\n",
      "Processing Nair2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/4kkjfoavkg1w\n",
      "Successfully processed Nair2020.pdf with 11 sections\n",
      "Processing OH2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/f5qve039ijbe\n",
      "Successfully processed OH2023.pdf with 12 sections\n",
      "Processing Salman2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/r18kq5ttg9tz\n",
      "Successfully processed Salman2023.pdf with 10 sections\n",
      "Processing Silva2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/xf3fpkk58qpd\n",
      "Successfully processed Silva2023.pdf with 11 sections\n",
      "Processing Temple2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/le3xvw7vjdhi\n",
      "Successfully processed Temple2021.pdf with 14 sections\n",
      "Processing Weber2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/pv1imc1u5fkt\n",
      "Successfully processed Weber2021.pdf with 3 sections\n",
      "Processing Xiang2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/mc83tb4cfkby\n",
      "Successfully processed Xiang2022.pdf with 6 sections\n",
      "Processing Yu2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/gdxsv0k2zadd\n",
      "Successfully processed Yu2021.pdf with 7 sections\n",
      "Processing alves2020-icpe.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/6ee9hk6t2aox\n",
      "Successfully processed alves2020-icpe.pdf with 11 sections\n",
      "Processing ballesteros2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/m8h0d5vafgoo\n",
      "Successfully processed ballesteros2021.pdf with 10 sections\n",
      "Processing chen2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/hzei2g2opzft\n",
      "Successfully processed chen2020.pdf with 10 sections\n",
      "Processing chen2023.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/m27t811mn8ot\n",
      "Successfully processed chen2023.pdf with 12 sections\n",
      "Processing damasceno2019.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/d3rydg66pfxp\n",
      "Successfully processed damasceno2019.pdf with 9 sections\n",
      "Processing ghofrani2019.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/91yd6p0tq8g1\n",
      "Successfully processed ghofrani2019.pdf with 9 sections\n",
      "Processing lesoil2021-icps.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/mhkp3q5dv953\n",
      "Successfully processed lesoil2021-icps.pdf with 13 sections\n",
      "Processing lesoil2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/tsmkd2xjizam\n",
      "Successfully processed lesoil2021.pdf with 8 sections\n",
      "Processing lesoil2022-icps.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/aw02kpmeukh6\n",
      "Successfully processed lesoil2022-icps.pdf with 8 sections\n",
      "Processing li2020-ase.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/5elsp0qbr8ke\n",
      "Successfully processed li2020-ase.pdf with 12 sections\n",
      "Processing li2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/dh9blvnl4uhx\n",
      "Successfully processed li2020.pdf with 11 sections\n",
      "Processing martin2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/rbl448b5gb5u\n",
      "Successfully processed martin2021.pdf with 10 sections\n",
      "Processing mehlstäubl2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/st2d18jswpp3\n",
      "Successfully processed mehlstäubl2022.pdf with 9 sections\n",
      "Processing nascimento2021-bigdata.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/q5bjglhxtlue\n",
      "Successfully processed nascimento2021-bigdata.pdf with 7 sections\n",
      "Processing schmid2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/m4c6rgf8psxh\n",
      "Successfully processed schmid2022.pdf with 13 sections\n",
      "Processing shu2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/17ifts062jvr\n",
      "Successfully processed shu2020.pdf with 8 sections\n",
      "Processing silva2020.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/gg11cf88emgn\n",
      "Successfully processed silva2020.pdf with 11 sections\n",
      "Processing silva2021-icps.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/b898ykzazjco\n",
      "Successfully processed silva2021-icps.pdf with 10 sections\n",
      "Processing sree-kumar2021.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/3q5brvgx4cv2\n",
      "Successfully processed sree-kumar2021.pdf with 8 sections\n",
      "Processing temple2019.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/knf4neyefd21\n",
      "Successfully processed temple2019.pdf with 12 sections\n",
      "Processing tërnava2022.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/g0r31gmbpsph\n",
      "Successfully processed tërnava2022.pdf with 12 sections\n",
      "Processing valov2020-icpe.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/mleyhpc302wz\n",
      "Successfully processed valov2020-icpe.pdf with 11 sections\n",
      "Processing david2024-splc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/f4vo02nnybqn\n",
      "Successfully processed david2024-splc.pdf with 8 sections\n",
      "Processing hugo2021-tse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/j535oinlbdi5\n",
      "Successfully processed hugo2021-tse.pdf with 11 sections\n",
      "Processing jose-miguel2023-jss.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/k9x1pxf9plfg\n",
      "Successfully processed jose-miguel2023-jss.pdf with 13 sections\n",
      "Processing larissa2024-hpdc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/44x5udwcs1zw\n",
      "Successfully processed larissa2024-hpdc.pdf with 13 sections\n",
      "Processing lukas2024-splc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/ku2xwlw5exo8\n",
      "Successfully processed lukas2024-splc.pdf with 11 sections\n",
      "Processing mathieu2023-splc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/3ef8nyuvqkue\n",
      "Successfully processed mathieu2023-splc.pdf with 4 sections\n",
      "Processing mukelabai2023-tse.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/vj5239oyng68\n",
      "Successfully processed mukelabai2023-tse.pdf with 11 sections\n",
      "Processing shaghayegh2022-splc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/w5bcipmpwj88\n",
      "Successfully processed shaghayegh2022-splc.pdf with 13 sections\n",
      "Processing tamim2024-splc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/l8neyg2k7qyi\n",
      "Successfully processed tamim2024-splc.pdf with 15 sections\n",
      "Processing xhevahire2023-sac.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/jllk9nwyfjcu\n",
      "Successfully processed xhevahire2023-sac.pdf with 11 sections\n",
      "Processing yuanjie2023-ase.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/trvuj2z3k091\n",
      "Successfully processed yuanjie2023-ase.pdf with 9 sections\n",
      "Processing Dorn2023ese.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/m272nv5mfz4h\n",
      "Successfully processed Dorn2023ese.pdf with 11 sections\n",
      "Processing Kaltenecker2023ese.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/qm1n5fyswf6f\n",
      "Successfully processed Kaltenecker2023ese.pdf with 11 sections\n",
      "Processing Vitui2021ese.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/lh4ri66wp5j3\n",
      "Successfully processed Vitui2021ese.pdf with 11 sections\n",
      "Processing cao2023ase.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/v3qkkhumyag1\n",
      "Successfully processed cao2023ase.pdf with 9 sections\n",
      "Processing li2019_ssm.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/wl417vlcnr1w\n",
      "Successfully processed li2019_ssm.pdf with 10 sections\n",
      "Processing li2023_scis.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/8aa4kjguk1qn\n",
      "Successfully processed li2023_scis.pdf with 11 sections\n",
      "Processing liang2024cc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/x51nvfdkltp2\n",
      "Successfully processed liang2024cc.pdf with 7 sections\n",
      "Processing lima2022ese.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/eushycjio4zs\n",
      "Successfully processed lima2022ese.pdf with 12 sections\n",
      "Processing marcén2022ssm.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/61yexxk2km3a\n",
      "Successfully processed marcén2022ssm.pdf with 11 sections\n",
      "Processing metzger2024computing.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/pbzp7ddveeov\n",
      "Successfully processed metzger2024computing.pdf with 13 sections\n",
      "Processing peng2023ese.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/okxssoc8zr96\n",
      "Successfully processed peng2023ese.pdf with 14 sections\n",
      "Processing safdar2020_ase.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/kehwxgladb2q\n",
      "Successfully processed safdar2020_ase.pdf with 5 sections\n",
      "Processing sakhrawi2019_cc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/7xee9010girm\n",
      "Successfully processed sakhrawi2019_cc.pdf with 8 sections\n",
      "Processing seewal2021_ijpp.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/m4qwv56q6k30\n",
      "Successfully processed seewal2021_ijpp.pdf with 10 sections\n",
      "Processing sewal2024cc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/fwc69tvyjc9e\n",
      "Successfully processed sewal2024cc.pdf with 5 sections\n",
      "Processing tipu2022_cc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/t8c55tt0ubjy\n",
      "Successfully processed tipu2022_cc.pdf with 8 sections\n",
      "Processing vázquez-ingelmo2020_cc.pdf with Gemini Lite...\n",
      "Arquivo enviado: files/8msekx0w3b5x\n",
      "Successfully processed vázquez-ingelmo2020_cc.pdf with 9 sections\n"
     ]
    }
   ],
   "source": [
    "#6) global llms \n",
    "db_name = \"results/extern_llm-gemini.db\"\n",
    "model_names = [\"gemini-2.5-flash-preview-05-20\", \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"]\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API\")\n",
    "start = time.time()\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')\n",
    "PDFHandler.create_tables(conn)\n",
    "\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "    print(f\"Processing {name} with Gemini Lite...\")\n",
    "    upload_pdf = upload_pdf_to_gemini(path)\n",
    "    prompt = PDFHandler.llm_prompt\n",
    "    \n",
    "    if upload_pdf is None:\n",
    "        print(f\"Error uploading PDF: {name}\")\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    doc = PDFHandler.try_open(path)\n",
    "    if doc is None:\n",
    "        print(f\"Error opening the PDF: {name}\")\n",
    "        continue\n",
    "        \n",
    "    text, page_count = PDFHandler.simple_extraction(doc)\n",
    "    try:\n",
    "        response = model.generate_content([prompt, upload_pdf])\n",
    "        response_text = response.text\n",
    "        json_from_response = extract_json_from_response(response_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name} with Gemini: {e}\")\n",
    "        continue\n",
    "\n",
    "    section_arr = []\n",
    "    number_found = False\n",
    "    for section in json_from_response.get(\"sections\", []):\n",
    "        if section['section_number']:\n",
    "            pattern = rf\"({re.escape(section['section_number'])})\\.?\\s*({re.escape(section['section_name'])})\"\n",
    "            number_found = True\n",
    "        else:\n",
    "            pattern = rf\"({re.escape(section['section_name'])})\"\n",
    "\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            all_section=section.get('all_section', '')\n",
    "            section_number=section.get('section_number', '')\n",
    "            section_title=section.get('section_name', '')\n",
    "            position=match.start()\n",
    "\n",
    "            section = SectionInfo(\n",
    "                all_section=all_section,\n",
    "                section_number=section_number,\n",
    "                section_title=section_title,\n",
    "                position=position,\n",
    "            )\n",
    "            section_arr.append(section)\n",
    "\n",
    "    if not section_arr:\n",
    "        print(f\"No sections found in text for {name}\")\n",
    "        continue\n",
    "    pdf_name = os.path.basename(path)\n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_result = cursor.fetchone()\n",
    "    if pdf_result:\n",
    "        pdf_id = pdf_result[0]\n",
    "    else:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "    PDFHandler.insert_section_into_sqlite(conn, section_arr, pdf_id)\n",
    "    print(f\"Successfully processed {name} with {len(section_arr)} sections\")\n",
    "    sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7) ORC extraction\n",
    "db_name = \"results/ORC_tag_extraction.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "PDFHandler.create_tables(conn)\n",
    "start = time.time()\n",
    "for path, name in zip(all_file_paths, all_file_names):\n",
    "\n",
    "    pdf_name = os.path.basename(path)\n",
    "    \n",
    "    cursor.execute(\"SELECT id FROM pdfs WHERE pdf_name = ?\", (pdf_name,))\n",
    "    pdf_id = cursor.fetchone()\n",
    "        \n",
    "    if not pdf_id:\n",
    "        cursor.execute(\"INSERT INTO pdfs (pdf_name) VALUES (?)\", (pdf_name,))\n",
    "        pdf_id = cursor.lastrowid\n",
    "\n",
    "    try:\n",
    "        sections = PDFHandler.orc_extraction_html(path)\n",
    "        if not sections:\n",
    "            print(f\"No sections found for {name} using ORC extraction.\")\n",
    "            continue\n",
    "        sections = [section for section in sections if section.section_title.strip() != \"\"]\n",
    "\n",
    "        PDFHandler.insert_section_into_sqlite(conn, sections, pdf_id)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>section_number</th>\n",
       "      <th>section_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amraoui2022_splc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amraoui2022_splc</td>\n",
       "      <td>2</td>\n",
       "      <td>FROM PARTIAL KNOWLEDGE TO AN SPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amraoui2022_splc</td>\n",
       "      <td>3</td>\n",
       "      <td>DESIGNING AN EVOLVABLE SPL WITH PARTIAL KNOWLEDGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amraoui2022_splc</td>\n",
       "      <td>4</td>\n",
       "      <td>APPLICATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amraoui2022_splc</td>\n",
       "      <td>5</td>\n",
       "      <td>DISCUSSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Vitui2021ese</td>\n",
       "      <td>5</td>\n",
       "      <td>Case Study Results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Vitui2021ese</td>\n",
       "      <td>6</td>\n",
       "      <td>Discussions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Vitui2021ese</td>\n",
       "      <td>7</td>\n",
       "      <td>Threats to Validity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Vitui2021ese</td>\n",
       "      <td>8</td>\n",
       "      <td>Related Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Vitui2021ese</td>\n",
       "      <td>9</td>\n",
       "      <td>Conclusions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name section_number  \\\n",
       "0    amraoui2022_splc              1   \n",
       "1    amraoui2022_splc              2   \n",
       "2    amraoui2022_splc              3   \n",
       "3    amraoui2022_splc              4   \n",
       "4    amraoui2022_splc              5   \n",
       "..                ...            ...   \n",
       "684      Vitui2021ese              5   \n",
       "685      Vitui2021ese              6   \n",
       "686      Vitui2021ese              7   \n",
       "687      Vitui2021ese              8   \n",
       "688      Vitui2021ese              9   \n",
       "\n",
       "                                          section_name  \n",
       "0                                         INTRODUCTION  \n",
       "1                     FROM PARTIAL KNOWLEDGE TO AN SPL  \n",
       "2    DESIGNING AN EVOLVABLE SPL WITH PARTIAL KNOWLEDGE  \n",
       "3                                          APPLICATION  \n",
       "4                                           DISCUSSION  \n",
       "..                                                 ...  \n",
       "684                                 Case Study Results  \n",
       "685                                        Discussions  \n",
       "686                                Threats to Validity  \n",
       "687                                       Related Work  \n",
       "688                                        Conclusions  \n",
       "\n",
       "[689 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pdf_name section_number  \\\n",
      "0                Krishna2021              1   \n",
      "1                Krishna2021              2   \n",
      "2                Krishna2021              3   \n",
      "3                Krishna2021              4   \n",
      "4                Krishna2021              5   \n",
      "...                      ...            ...   \n",
      "6885  vázquez-ingelmo2020_cc              2   \n",
      "6886  vázquez-ingelmo2020_cc              3   \n",
      "6887  vázquez-ingelmo2020_cc              4   \n",
      "6888  vázquez-ingelmo2020_cc              6   \n",
      "6889  vázquez-ingelmo2020_cc              7   \n",
      "\n",
      "                            section_title          source_db  \n",
      "0                            INTRODUCTION  specific_regex.db  \n",
      "1                              MOTIVATION  specific_regex.db  \n",
      "2       DEFINITIONS AND PROBLEM STATEMENT  specific_regex.db  \n",
      "3     BEETLE: BELLWETHER TRANSFER LEARNER  specific_regex.db  \n",
      "4         OTHER TRANSFER LEARNING METHODS  specific_regex.db  \n",
      "...                                   ...                ...  \n",
      "6885                           Background    tagged_regex.db  \n",
      "6886                          Methodology    tagged_regex.db  \n",
      "6887   Workflow for automatically setting    tagged_regex.db  \n",
      "6888                           Discussion    tagged_regex.db  \n",
      "6889                          Conclusions    tagged_regex.db  \n",
      "\n",
      "[6890 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "db_files = glob.glob(\"results/*.db\")\n",
    "dfs = []\n",
    "for db_file in db_files:\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    query = f\"\"\"SELECT pdf_name, section_number, section_title,\n",
    "     '{os.path.basename(db_file)}' as source_db\n",
    "     FROM extracted_text JOIN pdfs ON extracted_text.pdf_id = pdfs.id\"\"\"\n",
    "    try:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        # Remove this line since you're already adding source_db in the SQL query\n",
    "        # df['source_db'] = os.path.basename(db_file)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {db_file}: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if dfs:\n",
    "    all_data = pd.concat(dfs, ignore_index=True)\n",
    "    all_data['pdf_name'] = all_data['pdf_name'].str[:-4]\n",
    "    all_data.to_parquet(\"results/section_grouped.parquet\", index=False)\n",
    "    print(all_data)\n",
    "else:\n",
    "    print(\"No data loaded from databases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
